{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "load_model = False\n",
    "train_model = True\n",
    "save_preprocessing = True #add\n",
    "load_preprocessing = False #add\n",
    "save_results = True\n",
    "predict_train = False\n",
    "predict_dev = True\n",
    "\n",
    "run_toy = False\n",
    "toy_size = 1000\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "VERSION=\"train-on-drop-only\"\n",
    "t5_model = 't5-small'\n",
    "\n",
    "warmup_steps = 10 #1e4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47S35TVwgIeG",
    "tags": []
   },
   "source": [
    "# Using T5 on DROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUEAtP-egIeI"
   },
   "source": [
    "#### Package installs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "xKtbsamsidKs"
   },
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece\n",
    "!pip install --quiet wget\n",
    "!pip install --quiet datasets\n",
    "#!pip install --quiet ipywidgets\n",
    "#!pip install --quiet tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAC1x24qgIeJ"
   },
   "source": [
    "#### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyexkfSDij_3",
    "outputId": "6f764bbb-097b-4fc0-dd92-bfe8b5a65292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 13 03:17:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   56C    P8    50W / 420W |    589MiB / 24265MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1355      G   /usr/lib/xorg/Xorg                 59MiB |\n",
      "|    0   N/A  N/A      2161      G   /usr/lib/xorg/Xorg                274MiB |\n",
      "|    0   N/A  N/A      2342      G   /usr/bin/gnome-shell               52MiB |\n",
      "|    0   N/A  N/A     41258      G   ...AAAAAAAAA= --shared-files       25MiB |\n",
      "|    0   N/A  N/A    655630      G   /usr/bin/nvidia-settings           16MiB |\n",
      "|    0   N/A  N/A   1260506      G   ...AAAAAAAAA= --shared-files      140MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2EQCkymgIeK"
   },
   "source": [
    "#### Download drop_eval module and set directories\n",
    "\n",
    "https://github.com/allenai/allennlp-reading-comprehension/blob/master/allennlp_rc/eval/drop_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xME0lIMVgIeK",
    "outputId": "161c6687-c3c8-40c2-a9cd-efe68926a933",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-13 03:17:49--  https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11222 (11K) [text/plain]\n",
      "Saving to: ‘drop_eval.py’\n",
      "\n",
      "drop_eval.py        100%[===================>]  10.96K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2021-07-13 03:17:50 (1.51 MB/s) - ‘drop_eval.py’ saved [11222/11222]\n",
      "\n",
      "!!!!!train-on-drop-only directory already created locally -- CAUTION -- this run may overwrite existing data!!!!!\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py -O drop_eval.py\n",
    "\n",
    "#set directories\n",
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    !mkdir data\n",
    "data_dir = f\"./data/{VERSION}/{t5_model}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    !mkdir $data_dir\n",
    "else:\n",
    "    if save_model: print(f'!!!!!{VERSION} directory already created locally -- CAUTION -- this run may overwrite existing data!!!!!')\n",
    "    else: print('NOTE: save_model == FALSE, this execution will not save the model locally')\n",
    "    \n",
    "results_dir = f\"{data_dir}/results/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    !mkdir $results_dir\n",
    "\n",
    "log_dir = f\"{data_dir}/experiments/logs\"\n",
    "save_path = f\"{data_dir}/experiments/models\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFbTSPkUgIeK"
   },
   "source": [
    "#### set directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ADai1tgIeL"
   },
   "source": [
    "#### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4w1GhOTfgIeM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 03:17:50.511885: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jun__2_19:15:15_PDT_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.48\n",
      "Build cuda_11.4.r11.4/compiler.30033411_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 03:17:51.605305: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-13 03:17:51.616929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:51.617700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-13 03:17:51.617715: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 03:17:51.619806: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-13 03:17:51.619831: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-13 03:17:51.620940: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-13 03:17:51.621069: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-13 03:17:51.621331: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-13 03:17:51.621777: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-13 03:17:51.621860: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-13 03:17:51.621915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:51.622669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:51.623385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow.keras as keras\n",
    "import drop_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm,trange\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "assert len(tf.config.list_physical_devices(\"GPU\")) > 0, \"No GPU found by Tensorflow\"\n",
    "\n",
    "if(run_toy): print(f'Running on {toy_size:,} records for development run')\n",
    "    \n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5goXuHR1gIeM"
   },
   "source": [
    "#### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XdP6lcFegIeM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5forDrop(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esxfDrXO66Bz"
   },
   "source": [
    "#### Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r08M8aqE65_M",
    "outputId": "6fa4e62d-e0a1-419d-f167-370905df422c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 03:17:59.304116: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-13 03:17:59.305402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.307852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-13 03:17:59.307981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.309926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.311474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-13 03:17:59.311521: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-13 03:17:59.642898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-13 03:17:59.642921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-13 03:17:59.642925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-13 03:17:59.643071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.643924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.644661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-13 03:17:59.645371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21726 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2021-07-13 03:17:59.892465: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-07-13 03:17:59.960044: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-13 03:18:00.430087: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-13 03:18:00.430124: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing T5forDrop.\n",
      "\n",
      "All the layers of T5forDrop were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5forDrop for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "#replace numbers with special tokens\n",
    "numbers = {'additional_special_tokens':['1','2','3','4','5','6','7','8','9','0']}\n",
    "num_tokens_added = tokenizer.add_special_tokens(numbers)\n",
    "\n",
    "\n",
    "model = T5forDrop.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIt7bbI8gIeN"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy(dataset,toy_size=1000):\n",
    "    df = dataset.to_pandas()\n",
    "    df = df.head(toy_size)\n",
    "    return Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaxF09BQgIeO",
    "outputId": "7c233bba-6248-40ef-b87f-6fb31d5a42df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n",
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:  {'section_id': Value(dtype='string', id=None), 'query_id': Value(dtype='string', id=None), 'passage': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers_spans': Sequence(feature={'spans': Value(dtype='string', id=None), 'types': Value(dtype='string', id=None)}, length=-1, id=None)}\n",
      "\n",
      "\n",
      "Example data from the dataset: \n",
      " {'section_id': 'nfl_1184', 'query_id': 'f37e81fa-ef7b-4583-b671-762fc433faa9', 'passage': \" Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for a Week 16 duel with the Houston Texans.  Oakland would get the early lead in the first quarter as quarterback JaMarcus Russell completed a 20-yard touchdown pass to rookie wide receiver Chaz Schilens.  The Texans would respond with fullback Vonta Leach getting a 1-yard touchdown run, yet the Raiders would answer with kicker Sebastian Janikowski getting a 33-yard and a 30-yard field goal.  Houston would tie the game in the second quarter with kicker Kris Brown getting a 53-yard and a 24-yard field goal. Oakland would take the lead in the third quarter with wide receiver Johnnie Lee Higgins catching a 29-yard touchdown pass from Russell, followed up by an 80-yard punt return for a touchdown.  The Texans tried to rally in the fourth quarter as Brown nailed a 40-yard field goal, yet the Raiders' defense would shut down any possible attempt.\", 'question': 'Who scored the first touchdown of the game?', 'answers_spans': {'spans': ['Chaz Schilens', 'JaMarcus Russell'], 'types': ['span', 'span']}}\n"
     ]
    }
   ],
   "source": [
    "train_dataset_full = load_dataset('drop', split='train')\n",
    "valid_dataset_full = load_dataset('drop', split='validation')\n",
    "\n",
    "print('Dataset features: ',train_dataset_full.features)\n",
    "\n",
    "#reduce data to toy size if run_toy flag is set\n",
    "if(run_toy):\n",
    "    train_dataset = make_toy(train_dataset_full)\n",
    "    valid_dataset = make_toy(valid_dataset_full)\n",
    "\n",
    "else:\n",
    "    train_dataset = train_dataset_full\n",
    "    valid_dataset = valid_dataset_full\n",
    "    \n",
    "#check out one record\n",
    "data = next(iter(valid_dataset))\n",
    "print(\"\\n\\nExample data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo9sZK0bgIeS"
   },
   "source": [
    "#### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datset size: 77,400 records\n",
      "Validation datset size: 9,535 records\n",
      "Batch size: 16\n",
      "Total Steps: 4,838\n",
      "Total Validation Steps: 596\n"
     ]
    }
   ],
   "source": [
    "steps = int(np.ceil(len(train_dataset)/batch_size))\n",
    "valid_steps = int(np.ceil(len(valid_dataset)/batch_size))\n",
    "print('Training datset size: {:,} records'.format(len(train_dataset)))\n",
    "print('Validation datset size: {:,} records'.format(len(valid_dataset)))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print(\"Total Steps: {:,}\".format(steps))\n",
    "print(\"Total Validation Steps: {:,}\".format(valid_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZCcTPA0gIeS"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GnCSjtGwgIeT"
   },
   "outputs": [],
   "source": [
    "def encode(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "    context = example['passage']\n",
    "    question = example['question']\n",
    "    \n",
    "    answer = example['answers_spans']['spans']\n",
    "    answer_type = example['answers_spans']['types']\n",
    "    \n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)}\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus}\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention,\n",
    "                }\n",
    "    return outputs\n",
    "    \n",
    "def to_tf_dataset(dataset):\n",
    "    '''convert from arrow to TF dataset'''\n",
    "    \n",
    "    columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "    dataset.set_format(type='tensorflow', columns=columns)\n",
    "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,}\n",
    "    return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None]),}\n",
    "    ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "    return ds\n",
    "\n",
    "def create_dataset(dataset, cache_path=None, batch_size=batch_size, \n",
    "                   buffer_size= 1000, shuffling=True):\n",
    "    '''returns a padded_batch tf dataset'''\n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.padded_batch(batch_size)\n",
    "#     dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xiO1_gwgIeT",
    "outputId": "193cc551-b130-4c86-f566-e3d62cd1ee84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c52c06e2354f1b8bdb7627ced946be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2126: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4198ddcad11043f3a3225b7d969276a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9535.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset schema:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'decoder_attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess data\n",
    "train_ds = train_dataset.map(encode)\n",
    "valid_ds = valid_dataset.map(encode)\n",
    "\n",
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_train_ds = tf_train_ds.repeat(epochs)\n",
    "\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "\n",
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)\n",
    "\n",
    "print('dataset schema:')\n",
    "tf_train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHAi1i2BgIeV"
   },
   "source": [
    "#### Callbacks and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_model = 128\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YsCNpoMEgIeV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 03:30:56.963185: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-13 03:30:56.963235: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-07-13 03:30:56.963295: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-07-13 03:30:56.964584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64::/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2021-07-13 03:30:56.965529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n",
      "2021-07-13 03:30:57.155287: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-07-13 03:30:57.155468: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "metrics = [drop_eval.get_metrics]#[tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc5HnwUwgIeV"
   },
   "source": [
    "#### Compile and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"t5for_drop\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  16449536  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  18881280  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  25175808  \n",
      "=================================================================\n",
      "Total params: 60,506,626\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer)#, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3b8ff1cce3f28ba8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3b8ff1cce3f28ba8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjHtw6LogIeV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0ae45d6880>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0ae45d6880>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /home/omar/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-13 03:31:39.642035: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-13 03:31:39.825323: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3504000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849/4838 [==========>...................] - ETA: 4:51 - loss: 0.5574 - lr: 3.2318e-04"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    model.fit(tf_train_ds, epochs=epochs, steps_per_epoch=steps, callbacks=callbacks, \n",
    "              validation_data=tf_valid_ds, validation_steps=valid_steps,verbose=1)\n",
    "    if(save_model):\n",
    "        model.save_pretrained(save_path)\n",
    "        print('Training complete, model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqxSSq06bZct"
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_weights(save_path+'/tf_model.h5')\n",
    "    print(f'Model loaded from {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjsHiiSldUFa"
   },
   "source": [
    "#### Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(ds,model,tokenizer):\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(total=batch_size*len(list(ds.as_numpy_iterator()))) as bar:\n",
    "        for batch in ds:\n",
    "            input_ids = batch['input_ids']\n",
    "            output = model.generate(input_ids)\n",
    "\n",
    "            for i in range(output.shape[0]):\n",
    "                single_pred = tokenizer.decode(output[i])\n",
    "                single_pred = single_pred.replace('<pad>','')\n",
    "                single_pred = single_pred.replace('</s>','')\n",
    "                single_pred = single_pred.strip()\n",
    "\n",
    "                preds.append(single_pred)\n",
    "                bar.update(1)\n",
    "    return preds\n",
    "\n",
    "def evaluate(df):\n",
    "    EM = []\n",
    "    F1 = []\n",
    "    \n",
    "    \n",
    "    for predicted,gold in tqdm(zip(df['predicted'],df['answers_spans'])):\n",
    "\n",
    "        best_EM = 0\n",
    "        best_F1 = 0\n",
    "\n",
    "        for potential_answer in gold['spans']:\n",
    "            metrics = drop_eval.get_metrics(predicted=predicted,gold=potential_answer)\n",
    "\n",
    "            if metrics[1] > best_F1:\n",
    "                best_EM = metrics[0]\n",
    "                best_F1 = metrics[1]\n",
    "\n",
    "        EM.append(best_EM)\n",
    "        F1.append(best_F1)\n",
    "        \n",
    "    df['EM'] = EM\n",
    "    df['F1'] = F1\n",
    "    \n",
    "    print('Exact Match: {:0.4f}, F1: {:0.4f}'.format(df.EM.mean(),df.F1.mean()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_train:\n",
    "    print('Making Train Predictions...')\n",
    "    preds = batch_predict(ds=tf_train_ds,model=model,tokenizer=tokenizer)\n",
    "    train_df = train_dataset.to_pandas()\n",
    "    assert len(train_df) == len(preds) \"something wen't wrong\"\n",
    "    train_df['predicted'] = preds\n",
    "    print('Evaluating Train Predictions...')\n",
    "    train_df = evaluate(train_df)\n",
    "    if save_results:\n",
    "        train_df.to_pickle(results_dir+'drop_train'+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the training data saved to:\\n',save_dir)\n",
    "    \n",
    "if predict_dev:\n",
    "    print('Making Dev Predictions...')\n",
    "    preds = batch_predict(ds=tf_valid_ds,model=model,tokenizer=tokenizer)\n",
    "    valid_df = valid_dataset.to_pandas()\n",
    "    valid_df['predicted'] = preds\n",
    "    print('Evaluating Dev Predictions...')\n",
    "    valid_df = evaluate(valid_df)\n",
    "    if save_results:\n",
    "        valid_df.to_pickle(results_dir+'drop_validation'+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the validation data saved to:\\n',save_dir)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df[['query_id','passage','question','answers_spans','predicted','EM','F1']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(query_id,df):\n",
    "    print('question: ',df.loc[df.query_id == query_id,'question'].iloc[0])\n",
    "    print('passage: ',df.loc[df.query_id == query_id,'passage'].iloc[0])\n",
    "    print('\\npredicted answer: ',df.loc[df.query_id == query_id,'predicted'].iloc[0])\n",
    "    print('True answers: ',df.loc[df.query_id == query_id,'answers_spans'].iloc[0])\n",
    "    print('F1 score: ',df.loc[df.query_id == query_id,'F1'].iloc[0])\n",
    "    print('EM score: ',df.loc[df.query_id == query_id,'EM'].iloc[0])\n",
    "    \n",
    "    \n",
    "query_id = '0686d1f9-4a8e-4031-b665-49d425afb777'\n",
    "print_example(query_id,valid_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T5_DROP_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
