{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#decide which size of T5 to use\n",
    "t5_model = 't5-small'\n",
    "#choose whether to save the model that will be trained\n",
    "save_model = True\n",
    "VERSION=\"drop-60epochs-v0\"\n",
    "#choose whether to load the weights of a previously trained model\n",
    "load_model = False\n",
    "load_version = 'drop-v0'\n",
    "#choose whether to train the model\n",
    "train_model = True\n",
    "#choose whether to use a learning rate scheduler with warm-up & decay\n",
    "use_learning_schedule = True\n",
    "\n",
    "#choose whether to predict on train and/or dev sets\n",
    "predict_train = False\n",
    "predict_dev = True\n",
    "#choose whether to save prediction results to pickle folder\n",
    "save_results = True\n",
    "\n",
    "#choose whether to run a toy size dataset\n",
    "run_toy = False\n",
    "toy_size = 1000\n",
    "#choose number of epochs\n",
    "epochs = 60\n",
    "#choose batch size\n",
    "batch_size = 8\n",
    "#choose dataset to use\n",
    "dataset='drop' #acceptable values: drop, squad, hotpot_qa, augmented\n",
    "\n",
    "#additional parameters\n",
    "encoder_max_len = 512 #250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47S35TVwgIeG",
    "tags": []
   },
   "source": [
    "# Using T5 on DROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUEAtP-egIeI"
   },
   "source": [
    "#### Package installs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "xKtbsamsidKs"
   },
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece\n",
    "!pip install --quiet wget\n",
    "!pip install --quiet datasets\n",
    "#!pip install --quiet ipywidgets\n",
    "#!pip install --quiet tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAC1x24qgIeJ"
   },
   "source": [
    "#### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyexkfSDij_3",
    "outputId": "6f764bbb-097b-4fc0-dd92-bfe8b5a65292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 21 21:44:36 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   55C    P8    49W / 420W |    570MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1374      G   /usr/lib/xorg/Xorg                 59MiB |\n",
      "|    0   N/A  N/A      2176      G   /usr/lib/xorg/Xorg                267MiB |\n",
      "|    0   N/A  N/A      2365      G   /usr/bin/gnome-shell               47MiB |\n",
      "|    0   N/A  N/A      6221      G   ...AAAAAAAAA= --shared-files       27MiB |\n",
      "|    0   N/A  N/A    804308      G   ...AAAAAAAAA= --shared-files      144MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2EQCkymgIeK"
   },
   "source": [
    "#### Download drop_eval module and set directories\n",
    "\n",
    "https://github.com/allenai/allennlp-reading-comprehension/blob/master/allennlp_rc/eval/drop_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-21 21:44:37--  https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11222 (11K) [text/plain]\n",
      "Saving to: ‘drop_eval.py’\n",
      "\n",
      "drop_eval.py        100%[===================>]  10.96K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2021-07-21 21:44:37 (2.71 MB/s) - ‘drop_eval.py’ saved [11222/11222]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py -O drop_eval.py\n",
    "import os\n",
    "def create_dir(d,verbose=False):\n",
    "    if not os.path.exists(d):\n",
    "        !mkdir -p $d    \n",
    "        if verbose: print(f'created folder for {d}')\n",
    "    else:\n",
    "        if verbose: print(f'using existing folder for {d}\\nCAUTION -- this run may overwrite existing data!')\n",
    "    \n",
    "#set directories\n",
    "root_dir = './data'\n",
    "data_dir = f\"./data/{VERSION}/{t5_model}\"\n",
    "augmented_dir = f\"{root_dir}/augmented-data\"\n",
    "results_dir = f\"{data_dir}/results/\"\n",
    "log_dir = f\"{data_dir}/experiments/logs\"\n",
    "save_dir = f\"{data_dir}/experiments/models\"\n",
    "load_dir = f\"{root_dir}/{load_version}/{t5_model}/experiments/models\"\n",
    "\n",
    "create_dir(root_dir)\n",
    "create_dir(data_dir)\n",
    "create_dir(augmented_dir)\n",
    "create_dir(results_dir)\n",
    "create_dir(log_dir)\n",
    "create_dir(save_dir)\n",
    "\n",
    "if load_model:\n",
    "    assert os.path.exists(load_dir), 'Error - trying to load a model that doesnt exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ADai1tgIeL"
   },
   "source": [
    "#### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4w1GhOTfgIeM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 21:44:38.346529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jun__2_19:15:15_PDT_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.48\n",
      "Build cuda_11.4.r11.4/compiler.30033411_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 21:44:39.568672: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-21 21:44:39.580904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:39.581665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-21 21:44:39.581683: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-21 21:44:39.583875: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-21 21:44:39.583904: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-21 21:44:39.585045: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-21 21:44:39.585190: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-21 21:44:39.585465: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-21 21:44:39.585939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-21 21:44:39.586028: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-21 21:44:39.586097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:39.586868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:39.587578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow.keras as keras\n",
    "import drop_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm,trange\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "assert len(tf.config.list_physical_devices(\"GPU\")) > 0, \"No GPU found by Tensorflow\"\n",
    "\n",
    "if(run_toy): print(f'Running on {toy_size:,} records for development run')\n",
    "    \n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5goXuHR1gIeM"
   },
   "source": [
    "#### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XdP6lcFegIeM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class T5forDrop(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss')\n",
    "        self.F1_tracker= tf.keras.metrics.Mean(name='F1')\n",
    "        self.EM_tracker= tf.keras.metrics.Mean(name='EM')        \n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y_true = x[\"labels\"]\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            logits = outputs['logits']\n",
    "            y_pred = tf.math.argmax(tf.nn.softmax(logits,axis=2), axis = 2, output_type=tf.int32)\n",
    "            loss = tf.reduce_mean(outputs['loss'])            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # Calculate F1 and EM Metrics\n",
    "        # Create a word mask to not count the padding/sentence tokens\n",
    "        recall_word_mask = tf.math.logical_and(\n",
    "                    tf.math.not_equal(y_true,0)\n",
    "                    ,tf.math.not_equal(y_true,1))\n",
    "\n",
    "        precision_word_mask = tf.math.logical_and(\n",
    "                    tf.math.not_equal(y_pred,0)\n",
    "                    ,tf.math.not_equal(y_pred,1))\n",
    "\n",
    "        # match the tokens\n",
    "        match_token = tf.math.equal(y_true,y_pred)\n",
    "        recall_match = tf.math.logical_and(match_token,recall_word_mask) \n",
    "        precision_match = tf.math.logical_and(match_token,precision_word_mask) \n",
    "\n",
    "        # calculate score\n",
    "        precision_array = tf.math.reduce_sum(tf.cast(precision_match, tf.int32) ,axis=1)/tf.math.reduce_sum(tf.cast(precision_word_mask, tf.int32) ,axis=1)\n",
    "        recall_array = tf.math.reduce_sum(tf.cast(recall_match, tf.int32) ,axis=1)/tf.math.reduce_sum(tf.cast(recall_word_mask, tf.int32) ,axis=1)\n",
    "\n",
    "        P = tf.math.reduce_mean(precision_array)\n",
    "        R = tf.math.reduce_mean(recall_array)\n",
    "\n",
    "        EM = tf.math.reduce_mean(\n",
    "            tf.cast(tf.math.logical_and(\n",
    "                    tf.math.equal(precision_array,1)\n",
    "                    ,tf.math.equal(recall_array,1)), tf.int32))\n",
    "        F1 = 2*(P*R)/(P+R)\n",
    "        \n",
    "        '''\n",
    "        Note, since FP and FN are the same, \n",
    "        the F1 score is the same as Precision, Recall, \n",
    "        which is the average \"match\" score\n",
    "        '''\n",
    "\n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.F1_tracker.update_state(F1)   \n",
    "        self.EM_tracker.update_state(EM)           \n",
    "        self.compiled_metrics.update_state(y_true, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y_true = x[\"labels\"]\n",
    "        outputs = self(x, training=True)\n",
    "        logits = outputs['logits']\n",
    "        y_pred = tf.math.argmax(tf.nn.softmax(logits,axis=2), axis = 2, output_type=tf.int32)\n",
    "        loss = tf.reduce_mean(outputs['loss'])      \n",
    "        \n",
    "        # Calculate F1 and EM Metrics\n",
    "        # Create a word mask to not count the padding/sentence tokens\n",
    "        recall_word_mask = tf.math.logical_and(\n",
    "                    tf.math.not_equal(y_true,0)\n",
    "                    ,tf.math.not_equal(y_true,1))\n",
    "\n",
    "        precision_word_mask = tf.math.logical_and(\n",
    "                    tf.math.not_equal(y_pred,0)\n",
    "                    ,tf.math.not_equal(y_pred,1))\n",
    "\n",
    "        # match the tokens\n",
    "        match_token = tf.math.equal(y_true,y_pred)\n",
    "        recall_match = tf.math.logical_and(match_token,recall_word_mask) \n",
    "        precision_match = tf.math.logical_and(match_token,precision_word_mask) \n",
    "\n",
    "        # calculate score\n",
    "        precision_array = tf.math.reduce_sum(tf.cast(precision_match, tf.int32) ,axis=1)/tf.math.reduce_sum(tf.cast(precision_word_mask, tf.int32) ,axis=1)\n",
    "        recall_array = tf.math.reduce_sum(tf.cast(recall_match, tf.int32) ,axis=1)/tf.math.reduce_sum(tf.cast(recall_word_mask, tf.int32) ,axis=1)\n",
    "\n",
    "        P = tf.math.reduce_mean(precision_array)\n",
    "        R = tf.math.reduce_mean(recall_array)\n",
    "\n",
    "        EM = tf.math.reduce_mean(\n",
    "            tf.cast(tf.math.logical_and(\n",
    "                    tf.math.equal(precision_array,1)\n",
    "                    ,tf.math.equal(recall_array,1)), tf.int32))\n",
    "        F1 = 2*(P*R)/(P+R)\n",
    "\n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.F1_tracker.update_state(F1)   \n",
    "        self.EM_tracker.update_state(EM)           \n",
    "        self.compiled_metrics.update_state(y_true, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esxfDrXO66Bz"
   },
   "source": [
    "#### Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r08M8aqE65_M",
    "outputId": "6fa4e62d-e0a1-419d-f167-370905df422c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 21:44:41.668406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-21 21:44:41.669987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.672450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-21 21:44:41.672614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.674557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.676217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-21 21:44:41.676257: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-21 21:44:41.983035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-21 21:44:41.983061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-21 21:44:41.983065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-21 21:44:41.983226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.984041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.984793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 21:44:41.985494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21736 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2021-07-21 21:44:42.156903: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-07-21 21:44:42.228903: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-21 21:44:42.683370: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-21 21:44:42.683407: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing T5forDrop.\n",
      "\n",
      "All the layers of T5forDrop were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5forDrop for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "#replace numbers with special tokens\n",
    "numbers = {'additional_special_tokens':['1','2','3','4','5','6','7','8','9','0','<ss>','<sv>']}\n",
    "num_tokens_added = tokenizer.add_special_tokens(numbers)\n",
    "\n",
    "\n",
    "model = T5forDrop.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIt7bbI8gIeN"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy(dataset,toy_size=1000):\n",
    "    df = dataset.to_pandas()\n",
    "    df = df.head(toy_size)\n",
    "    return Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaxF09BQgIeO",
    "outputId": "7c233bba-6248-40ef-b87f-6fb31d5a42df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n",
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:  {'section_id': Value(dtype='string', id=None), 'query_id': Value(dtype='string', id=None), 'passage': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers_spans': Sequence(feature={'spans': Value(dtype='string', id=None), 'types': Value(dtype='string', id=None)}, length=-1, id=None)}\n",
      "\n",
      "\n",
      "Example data from the dataset: \n",
      " {'section_id': 'nfl_1184', 'query_id': 'f37e81fa-ef7b-4583-b671-762fc433faa9', 'passage': \" Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for a Week 16 duel with the Houston Texans.  Oakland would get the early lead in the first quarter as quarterback JaMarcus Russell completed a 20-yard touchdown pass to rookie wide receiver Chaz Schilens.  The Texans would respond with fullback Vonta Leach getting a 1-yard touchdown run, yet the Raiders would answer with kicker Sebastian Janikowski getting a 33-yard and a 30-yard field goal.  Houston would tie the game in the second quarter with kicker Kris Brown getting a 53-yard and a 24-yard field goal. Oakland would take the lead in the third quarter with wide receiver Johnnie Lee Higgins catching a 29-yard touchdown pass from Russell, followed up by an 80-yard punt return for a touchdown.  The Texans tried to rally in the fourth quarter as Brown nailed a 40-yard field goal, yet the Raiders' defense would shut down any possible attempt.\", 'question': 'Who scored the first touchdown of the game?', 'answers_spans': {'spans': ['Chaz Schilens', 'JaMarcus Russell'], 'types': ['span', 'span']}}\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"hotpot_qa\":\n",
    "    train_dataset_full = load_dataset(dataset,'distractor', split='train')\n",
    "    valid_dataset_full = load_dataset(dataset,'distractor', split='validation')\n",
    "elif dataset == 'augmented':\n",
    "    full_df = pd.read_pickle(augmented_dir+'/augmented_data.pkl')\n",
    "    train_dataset_full, valid_dataset_full = train_test_split(full_df,test_size=0.2)\n",
    "    train_dataset_full = Dataset.from_pandas(train_dataset_full)\n",
    "    valid_dataset_full = Dataset.from_pandas(valid_dataset_full)\n",
    "    \n",
    "else:\n",
    "    train_dataset_full = load_dataset(dataset, split='train')\n",
    "    valid_dataset_full = load_dataset(dataset, split='validation')\n",
    "\n",
    "print('Dataset features: ',train_dataset_full.features)\n",
    "\n",
    "#reduce data to toy size if run_toy flag is set\n",
    "if(run_toy):\n",
    "    train_dataset = make_toy(train_dataset_full)\n",
    "    valid_dataset = make_toy(valid_dataset_full)\n",
    "\n",
    "else:\n",
    "    train_dataset = train_dataset_full\n",
    "    valid_dataset = valid_dataset_full\n",
    "    \n",
    "#check out one record\n",
    "data = next(iter(valid_dataset))\n",
    "print(\"\\n\\nExample data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo9sZK0bgIeS"
   },
   "source": [
    "#### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datset size: 77,400 records\n",
      "Validation datset size: 9,535 records\n",
      "Batch size: 8\n",
      "Total Steps: 9,675\n",
      "Total Validation Steps: 1,192\n"
     ]
    }
   ],
   "source": [
    "steps = int(np.ceil(len(train_dataset)/batch_size))\n",
    "valid_steps = int(np.ceil(len(valid_dataset)/batch_size))\n",
    "print('Training datset size: {:,} records'.format(len(train_dataset)))\n",
    "print('Validation datset size: {:,} records'.format(len(valid_dataset)))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print(\"Total Steps: {:,}\".format(steps))\n",
    "print(\"Total Validation Steps: {:,}\".format(valid_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZCcTPA0gIeS"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GnCSjtGwgIeT"
   },
   "outputs": [],
   "source": [
    "def encode(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "    if dataset == 'drop':\n",
    "        context = example['passage']\n",
    "        question = example['question']\n",
    "\n",
    "        answer = example['answers_spans']['spans']\n",
    "        answer_type = example['answers_spans']['types']\n",
    "    elif dataset == 'squad':\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        \n",
    "        answer = example['answers']['text']\n",
    "        answer_type = 'text'\n",
    "    elif dataset == 'hotpot_qa':\n",
    "        context = ''\n",
    "        for sentence in example[\"context\"][\"sentences\"]:\n",
    "            context += \" \".join(sentence) + \" \"\n",
    "        question = example['question']\n",
    "        \n",
    "        answer = [example['answer']]\n",
    "        answer_type = 'text'    \n",
    "    elif dataset == 'augmented':\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        answer = [example['answer']]\n",
    "        answer_type = example['qtype']\n",
    "    \n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)}\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus}\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention,\n",
    "                }\n",
    "    return outputs\n",
    "    \n",
    "def to_tf_dataset(dataset):\n",
    "    '''convert from arrow to TF dataset'''\n",
    "    \n",
    "    columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "    dataset.set_format(type='tensorflow', columns=columns)\n",
    "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,}\n",
    "    return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None]),}\n",
    "    ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "    return ds\n",
    "\n",
    "def create_dataset(dataset, cache_path=None, batch_size=batch_size, \n",
    "                   buffer_size= 1000, shuffling=True):\n",
    "    '''returns a padded_batch tf dataset'''\n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.padded_batch(batch_size)\n",
    "#     dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xiO1_gwgIeT",
    "outputId": "193cc551-b130-4c86-f566-e3d62cd1ee84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e559796bed3499f89bbbf14745f6aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daddd0ee34ab40e6ae89a9f14e97eb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9535.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset schema:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'decoder_attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess data\n",
    "train_ds = train_dataset.map(encode)\n",
    "valid_ds = valid_dataset.map(encode)\n",
    "\n",
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_train_ds = tf_train_ds.repeat(epochs)\n",
    "\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "\n",
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)\n",
    "\n",
    "print('dataset schema:')\n",
    "tf_train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHAi1i2BgIeV"
   },
   "source": [
    "#### Callbacks and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Schedule to input into CustomLearningRateScheduler()\n",
    "def lr_schedule(training_steps, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if training_steps < __TOTAL_WARM_UP_STEPS:\n",
    "        # print(\"\\nWARM UP: Using Increasing Linear Function at Training Step:{}\".format(training_steps))\n",
    "        lr = ((MAX_LR - START_LR)/__TOTAL_WARM_UP_STEPS) * training_steps + START_LR # y = (m)x + b\n",
    "    else:\n",
    "        __CURRENT_DECAY_STEP = training_steps - __TOTAL_WARM_UP_STEPS\n",
    "        if DECAY == \"ExponentialDecay\":\n",
    "            # print(\"\\nDECAY: Using ExponentialDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = keras.optimizers.schedules.ExponentialDecay(\n",
    "                  initial_learning_rate=MAX_LR,\n",
    "                  decay_steps=__TOTAL_DECAY_STEPS,\n",
    "                  decay_rate=END_LR/MAX_LR)\n",
    "        elif DECAY == \"PiecewiseConstantDecay\":\n",
    "            # print(\"\\nDECAY: Using PiecewiseConstantDecay at Training Step:{}\".format(training_steps))\n",
    "            __CURRENT_DECAY_STEP = tf.Variable(__CURRENT_DECAY_STEP, trainable=False)\n",
    "            __DECAY_FN = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "                  __BOUNDARIES, __VALUES)\n",
    "        elif DECAY == \"PolynomialDecay\":\n",
    "            # print(\"\\nDECAY: Using PolynomialDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "                  MAX_LR,\n",
    "                  __TOTAL_DECAY_STEPS,\n",
    "                  END_LR,\n",
    "                  power=POWER)\n",
    "        elif DECAY == \"InverseTimeDecay\":\n",
    "            # print(\"DECAY: Using InverseTimeDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = keras.optimizers.schedules.InverseTimeDecay(\n",
    "                  MAX_LR, __TIME_DECAY, 1)\n",
    "        else:\n",
    "            print(\"Please Select a Decay Function\")\n",
    "            exit\n",
    "        lr = __DECAY_FN(__CURRENT_DECAY_STEP)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learning Rate Schedule Parameters\n",
    "WARM_UP_FRACTION = 1/10 #The fraction of the training steps that will be ramping up linearly to the max LR\n",
    "START_LR = 0.0005 # must be float\n",
    "MAX_LR = 0.001 # must be float\n",
    "END_LR = 0.0001 # must be float\n",
    "\n",
    "EPOCHS = epochs\n",
    "STEPS_PER_EPOCH = steps\n",
    "__TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "__TOTAL_WARM_UP_STEPS = __TOTAL_STEPS * WARM_UP_FRACTION\n",
    "__TOTAL_DECAY_STEPS = __TOTAL_STEPS - __TOTAL_WARM_UP_STEPS\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "# Decay Parameters\n",
    "# ExponentialDecay - None\n",
    "\n",
    "# PiecewiseConstantDecay\n",
    "NUM_BOUNDARIES = 10\n",
    "__BOUNDARY_STEP = __TOTAL_DECAY_STEPS/NUM_BOUNDARIES\n",
    "__BOUNDARIES = list(np.arange(0,__TOTAL_DECAY_STEPS+__BOUNDARY_STEP,__BOUNDARY_STEP))\n",
    "__PIECEWISE_STEP = (MAX_LR - END_LR)/(NUM_BOUNDARIES)\n",
    "__VALUES = list(np.arange(MAX_LR,END_LR-__PIECEWISE_STEP,-__PIECEWISE_STEP))\n",
    "\n",
    "# PolynomialDecay\n",
    "POWER = .5 # Must be > 1 to reach END_LR\n",
    "\n",
    "#InverseTimeDecay\n",
    "__TIME_DECAY = __TOTAL_DECAY_STEPS/(MAX_LR/END_LR-1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# Initialize Graphing\n",
    "decay_array = [\"ExponentialDecay\", \"PiecewiseConstantDecay\", \"PolynomialDecay\", \"InverseTimeDecay\"]\n",
    "x = range(__TOTAL_STEPS)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6),ncols=len(decay_array))\n",
    "fig.suptitle(f'Learing Rate Schedule', fontsize=14)\n",
    "ymax = max(START_LR,MAX_LR,END_LR)\n",
    "ymax *= 1.1\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('Learning Rate')\n",
    "for i,decay_type in enumerate(decay_array):\n",
    "    DECAY = decay_type\n",
    "    lr_values = []\n",
    "    for step in x:\n",
    "        lr_values.append(lr_schedule(step,0))\n",
    "    ax[i].plot(x,lr_values)\n",
    "    ax[i].set_title(decay_type, fontsize=14, pad=11)\n",
    "    ax[i].set_xlabel('Steps')\n",
    "    ax[i].set_ylim([0,ymax])\n",
    "    if i > 0:\n",
    "        ax[i].tick_params(which='both', left=False, labelleft=False)\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------------------\n",
    "\n",
    "# ACTION: Select Decay Type\n",
    "DECAY = \"PiecewiseConstantDecay\" #[\"ExponentialDecay\", \"PiecewiseConstantDecay\", \"PolynomialDecay\", \"InverseTimeDecay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.current_epoch += 1\n",
    "\n",
    "    def on_batch_begin(self, batch_step, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        total_steps = batch_step + self.current_epoch * steps\n",
    "        scheduled_lr = self.schedule(total_steps, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        # print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (total_steps, scheduled_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YsCNpoMEgIeV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 22:06:29.040666: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-21 22:06:29.040727: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-07-21 22:06:29.040830: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-07-21 22:06:29.042056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64::/usr/local/cuda/lib64\n",
      "2021-07-21 22:06:29.043571: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n",
      "2021-07-21 22:06:29.278568: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-07-21 22:06:29.278761: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_dir + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "if use_learning_schedule:\n",
    "    callbacks.append(CustomLearningRateScheduler(lr_schedule))\n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5,name='accuracy') ]#[drop_eval.get_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc5HnwUwgIeV"
   },
   "source": [
    "#### Compile and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"t5for_drop\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  16449536  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  18881280  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  25175808  \n",
      "=================================================================\n",
      "Total params: 60,506,630\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0005\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xqxSSq06bZct"
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_weights(load_dir+'/tf_model.h5')\n",
    "    print(f'Model loaded from {load_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9c4ebb79576d9e2f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9c4ebb79576d9e2f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wjHtw6LogIeV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 22:06:39.038567: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-21 22:06:39.301395: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3504000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9675/9675 [==============================] - 1079s 110ms/step - accuracy: 0.9902 - loss: 0.0994 - F1: nan - EM: 0.0000e+00 - lr: 5.4167e-04 - val_accuracy: 0.9641 - val_loss: 0.4383 - val_F1: 0.4047 - val_EM: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn, dropout_24_layer_call_and_return_conditional_losses, dropout_24_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses while saving (showing 5 of 1310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "   9/9675 [..............................] - ETA: 16:21 - accuracy: 0.9887 - loss: 0.1003 - F1: 0.3742 - EM: 0.0000e+00 - lr: 5.8337e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 22:24:54.833127: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-21 22:24:54.833145: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 110/9675 [..............................] - ETA: 17:36 - accuracy: 0.9907 - loss: 0.0938 - F1: 0.4750 - EM: 0.0000e+00 - lr: 5.8380e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 22:25:06.066244: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-07-21 22:25:06.070421: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-07-21 22:25:07.098630: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 275279 callback api events and 275992 activity events. \n",
      "2021-07-21 22:25:10.514786: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9923 - loss: 0.0809 - F1: 0.5131 - EM: 0.0000e+00 - lr: 6.2500e-04 - val_accuracy: 0.9661 - val_loss: 0.4531 - val_F1: 0.4330 - val_EM: 0.0000e+00\n",
      "Epoch 3/60\n",
      "9675/9675 [==============================] - 1049s 108ms/step - accuracy: 0.9933 - loss: 0.0742 - F1: nan - EM: 0.0000e+00 - lr: 7.0833e-04 - val_accuracy: 0.9656 - val_loss: 0.4158 - val_F1: 0.4626 - val_EM: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn, dropout_24_layer_call_and_return_conditional_losses, dropout_24_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses while saving (showing 5 of 1310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60\n",
      "9675/9675 [==============================] - 1045s 108ms/step - accuracy: 0.9935 - loss: 0.0712 - F1: nan - EM: 3.1008e-04 - lr: 7.9167e-04 - val_accuracy: 0.9645 - val_loss: 0.4315 - val_F1: nan - val_EM: 0.0000e+00\n",
      "Epoch 5/60\n",
      "9675/9675 [==============================] - 1044s 108ms/step - accuracy: 0.9938 - loss: 0.0696 - F1: nan - EM: 2.0672e-04 - lr: 8.7500e-04 - val_accuracy: 0.9666 - val_loss: 0.4214 - val_F1: 0.4483 - val_EM: 0.0000e+00\n",
      "Epoch 6/60\n",
      "9675/9675 [==============================] - 1044s 108ms/step - accuracy: 0.9938 - loss: 0.0688 - F1: nan - EM: 3.1008e-04 - lr: 9.5833e-04 - val_accuracy: 0.9667 - val_loss: 0.4653 - val_F1: 0.4434 - val_EM: 0.0000e+00\n",
      "Epoch 7/60\n",
      "9675/9675 [==============================] - 1061s 110ms/step - accuracy: 0.9943 - loss: 0.0658 - F1: nan - EM: 3.1008e-04 - lr: 9.1001e-04 - val_accuracy: 0.9648 - val_loss: 0.4895 - val_F1: 0.4490 - val_EM: 0.0000e+00\n",
      "Epoch 8/60\n",
      "9675/9675 [==============================] - 1062s 110ms/step - accuracy: 0.9944 - loss: 0.0640 - F1: 0.5824 - EM: 5.1680e-04 - lr: 9.1000e-04 - val_accuracy: 0.9672 - val_loss: 0.4703 - val_F1: 0.4726 - val_EM: 0.0000e+00\n",
      "Epoch 9/60\n",
      "9675/9675 [==============================] - 1062s 110ms/step - accuracy: 0.9946 - loss: 0.0622 - F1: nan - EM: 3.1008e-04 - lr: 9.1000e-04 - val_accuracy: 0.9667 - val_loss: 0.5042 - val_F1: 0.4599 - val_EM: 0.0000e+00\n",
      "Epoch 10/60\n",
      "9675/9675 [==============================] - 1069s 110ms/step - accuracy: 0.9948 - loss: 0.0608 - F1: 0.5969 - EM: 4.1344e-04 - lr: 9.1000e-04 - val_accuracy: 0.9655 - val_loss: 0.5386 - val_F1: 0.4393 - val_EM: 0.0000e+00\n",
      "Epoch 11/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9949 - loss: 0.0593 - F1: 0.6033 - EM: 7.2351e-04 - lr: 9.1000e-04 - val_accuracy: 0.9682 - val_loss: 0.5111 - val_F1: 0.4678 - val_EM: 0.0000e+00\n",
      "Epoch 12/60\n",
      "9675/9675 [==============================] - 1063s 110ms/step - accuracy: 0.9951 - loss: 0.0571 - F1: 0.6126 - EM: 7.2351e-04 - lr: 8.5601e-04 - val_accuracy: 0.9658 - val_loss: 0.5365 - val_F1: nan - val_EM: 0.0000e+00\n",
      "Epoch 13/60\n",
      "9675/9675 [==============================] - 1063s 110ms/step - accuracy: 0.9954 - loss: 0.0550 - F1: nan - EM: 8.2687e-04 - lr: 8.2000e-04 - val_accuracy: 0.9656 - val_loss: 0.5232 - val_F1: 0.4485 - val_EM: 0.0000e+00\n",
      "Epoch 14/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9956 - loss: 0.0536 - F1: 0.6262 - EM: 0.0018 - lr: 8.2000e-04 - val_accuracy: 0.9661 - val_loss: 0.4840 - val_F1: 0.4693 - val_EM: 0.0000e+00\n",
      "Epoch 15/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9957 - loss: 0.0525 - F1: 0.6322 - EM: 0.0016 - lr: 8.2000e-04 - val_accuracy: 0.9654 - val_loss: 0.5220 - val_F1: 0.4510 - val_EM: 0.0000e+00\n",
      "Epoch 16/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9958 - loss: 0.0514 - F1: 0.6392 - EM: 0.0020 - lr: 8.2000e-04 - val_accuracy: 0.9652 - val_loss: 0.5016 - val_F1: 0.4501 - val_EM: 0.0000e+00\n",
      "Epoch 17/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9960 - loss: 0.0500 - F1: nan - EM: 0.0025 - lr: 8.0200e-04 - val_accuracy: 0.9662 - val_loss: 0.5816 - val_F1: 0.4486 - val_EM: 0.0000e+00\n",
      "Epoch 18/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9962 - loss: 0.0478 - F1: nan - EM: 0.0026 - lr: 7.3000e-04 - val_accuracy: 0.9663 - val_loss: 0.5091 - val_F1: 0.4574 - val_EM: 0.0000e+00\n",
      "Epoch 19/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9963 - loss: 0.0465 - F1: 0.6630 - EM: 0.0024 - lr: 7.3000e-04 - val_accuracy: 0.9654 - val_loss: 0.5476 - val_F1: 0.4420 - val_EM: 0.0000e+00\n",
      "Epoch 20/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9965 - loss: 0.0454 - F1: nan - EM: 0.0034 - lr: 7.3000e-04 - val_accuracy: 0.9657 - val_loss: 0.5516 - val_F1: 0.4562 - val_EM: 0.0000e+00\n",
      "Epoch 21/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9966 - loss: 0.0444 - F1: 0.6755 - EM: 0.0049 - lr: 7.3000e-04 - val_accuracy: 0.9615 - val_loss: 0.5403 - val_F1: 0.4508 - val_EM: 0.0000e+00\n",
      "Epoch 22/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9967 - loss: 0.0434 - F1: nan - EM: 0.0033 - lr: 7.3000e-04 - val_accuracy: 0.9641 - val_loss: 0.5730 - val_F1: 0.4491 - val_EM: 0.0000e+00\n",
      "Epoch 23/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9969 - loss: 0.0415 - F1: 0.6888 - EM: 0.0057 - lr: 6.5801e-04 - val_accuracy: 0.9624 - val_loss: 0.5527 - val_F1: 0.4424 - val_EM: 0.0000e+00\n",
      "Epoch 24/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9971 - loss: 0.0401 - F1: nan - EM: 0.0070 - lr: 6.4000e-04 - val_accuracy: 0.9622 - val_loss: 0.5778 - val_F1: 0.4406 - val_EM: 0.0000e+00\n",
      "Epoch 25/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9972 - loss: 0.0392 - F1: 0.7053 - EM: 0.0087 - lr: 6.4000e-04 - val_accuracy: 0.9633 - val_loss: 0.6259 - val_F1: 0.4481 - val_EM: 0.0000e+00\n",
      "Epoch 26/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9974 - loss: 0.0381 - F1: nan - EM: 0.0094 - lr: 6.4000e-04 - val_accuracy: 0.9645 - val_loss: 0.5719 - val_F1: 0.4582 - val_EM: 0.0000e+00\n",
      "Epoch 27/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9975 - loss: 0.0373 - F1: 0.7187 - EM: 0.0117 - lr: 6.4000e-04 - val_accuracy: 0.9624 - val_loss: 0.5935 - val_F1: 0.4497 - val_EM: 0.0000e+00\n",
      "Epoch 28/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9976 - loss: 0.0361 - F1: nan - EM: 0.0110 - lr: 6.0400e-04 - val_accuracy: 0.9630 - val_loss: 0.5913 - val_F1: 0.4629 - val_EM: 0.0000e+00\n",
      "Epoch 29/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9978 - loss: 0.0342 - F1: nan - EM: 0.0158 - lr: 5.5000e-04 - val_accuracy: 0.9639 - val_loss: 0.6025 - val_F1: 0.4638 - val_EM: 0.0000e+00\n",
      "Epoch 30/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9979 - loss: 0.0334 - F1: nan - EM: 0.0203 - lr: 5.5000e-04 - val_accuracy: 0.9648 - val_loss: 0.6387 - val_F1: 0.4492 - val_EM: 0.0000e+00\n",
      "Epoch 31/60\n",
      "9675/9675 [==============================] - 1072s 111ms/step - accuracy: 0.9980 - loss: 0.0324 - F1: nan - EM: 0.0180 - lr: 5.5000e-04 - val_accuracy: 0.9615 - val_loss: 0.6315 - val_F1: 0.4389 - val_EM: 0.0000e+00\n",
      "Epoch 32/60\n",
      "9675/9675 [==============================] - 1064s 110ms/step - accuracy: 0.9981 - loss: 0.0317 - F1: nan - EM: 0.0220 - lr: 5.5000e-04 - val_accuracy: 0.9625 - val_loss: 0.6700 - val_F1: 0.4461 - val_EM: 0.0000e+00\n",
      "Epoch 33/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9982 - loss: 0.0309 - F1: nan - EM: 0.0247 - lr: 5.5000e-04 - val_accuracy: 0.9617 - val_loss: 0.6201 - val_F1: 0.4561 - val_EM: 0.0000e+00\n",
      "Epoch 34/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9984 - loss: 0.0290 - F1: nan - EM: 0.0322 - lr: 4.6001e-04 - val_accuracy: 0.9627 - val_loss: 0.6519 - val_F1: 0.4475 - val_EM: 0.0000e+00\n",
      "Epoch 35/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9985 - loss: 0.0280 - F1: 0.7819 - EM: 0.0352 - lr: 4.6000e-04 - val_accuracy: 0.9618 - val_loss: 0.6448 - val_F1: 0.4438 - val_EM: 0.0000e+00\n",
      "Epoch 36/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9986 - loss: 0.0272 - F1: 0.7896 - EM: 0.0365 - lr: 4.6000e-04 - val_accuracy: 0.9629 - val_loss: 0.6415 - val_F1: 0.4479 - val_EM: 0.0000e+00\n",
      "Epoch 37/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9986 - loss: 0.0265 - F1: 0.7952 - EM: 0.0428 - lr: 4.6000e-04 - val_accuracy: 0.9618 - val_loss: 0.6519 - val_F1: 0.4411 - val_EM: 0.0000e+00\n",
      "Epoch 38/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9987 - loss: 0.0259 - F1: 0.7991 - EM: 0.0416 - lr: 4.6000e-04 - val_accuracy: 0.9609 - val_loss: 0.7098 - val_F1: 0.4414 - val_EM: 0.0000e+00\n",
      "Epoch 39/60\n",
      "9675/9675 [==============================] - 1091s 113ms/step - accuracy: 0.9988 - loss: 0.0245 - F1: nan - EM: 0.0505 - lr: 4.0601e-04 - val_accuracy: 0.9612 - val_loss: 0.7516 - val_F1: 0.4403 - val_EM: 0.0000e+00\n",
      "Epoch 40/60\n",
      "9675/9675 [==============================] - 1086s 112ms/step - accuracy: 0.9989 - loss: 0.0232 - F1: 0.8197 - EM: 0.0650 - lr: 3.7000e-04 - val_accuracy: 0.9605 - val_loss: 0.7247 - val_F1: 0.4355 - val_EM: 0.0000e+00\n",
      "Epoch 41/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9990 - loss: 0.0224 - F1: 0.8248 - EM: 0.0674 - lr: 3.7000e-04 - val_accuracy: 0.9625 - val_loss: 0.7349 - val_F1: 0.4402 - val_EM: 0.0000e+00\n",
      "Epoch 42/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9990 - loss: 0.0219 - F1: nan - EM: 0.0744 - lr: 3.7000e-04 - val_accuracy: 0.9609 - val_loss: 0.6919 - val_F1: 0.4444 - val_EM: 0.0000e+00\n",
      "Epoch 43/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9991 - loss: 0.0212 - F1: 0.8348 - EM: 0.0795 - lr: 3.7000e-04 - val_accuracy: 0.9590 - val_loss: 0.8041 - val_F1: 0.4421 - val_EM: 0.0000e+00\n",
      "Epoch 44/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9992 - loss: 0.0205 - F1: nan - EM: 0.0837 - lr: 3.5200e-04 - val_accuracy: 0.9613 - val_loss: 0.7441 - val_F1: nan - val_EM: 0.0000e+00\n",
      "Epoch 45/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9993 - loss: 0.0190 - F1: nan - EM: 0.1013 - lr: 2.8000e-04 - val_accuracy: 0.9606 - val_loss: 0.7958 - val_F1: 0.4407 - val_EM: 0.0000e+00\n",
      "Epoch 46/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9993 - loss: 0.0182 - F1: 0.8568 - EM: 0.1120 - lr: 2.8000e-04 - val_accuracy: 0.9610 - val_loss: 0.8121 - val_F1: nan - val_EM: 0.0000e+00\n",
      "Epoch 47/60\n",
      "9675/9675 [==============================] - 1065s 110ms/step - accuracy: 0.9994 - loss: 0.0177 - F1: nan - EM: 0.1176 - lr: 2.8000e-04 - val_accuracy: 0.9594 - val_loss: 0.8438 - val_F1: 0.4453 - val_EM: 0.0000e+00\n",
      "Epoch 48/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9994 - loss: 0.0174 - F1: 0.8640 - EM: 0.1182 - lr: 2.8000e-04 - val_accuracy: 0.9601 - val_loss: 0.7985 - val_F1: 0.4417 - val_EM: 0.0000e+00\n",
      "Epoch 49/60\n",
      "9675/9675 [==============================] - 1070s 111ms/step - accuracy: 0.9995 - loss: 0.0168 - F1: 0.8697 - EM: 0.1293 - lr: 2.8000e-04 - val_accuracy: 0.9601 - val_loss: 0.8773 - val_F1: 0.4407 - val_EM: 0.0000e+00\n",
      "Epoch 50/60\n",
      "9675/9675 [==============================] - 1098s 113ms/step - accuracy: 0.9995 - loss: 0.0156 - F1: nan - EM: 0.1514 - lr: 2.0801e-04 - val_accuracy: 0.9598 - val_loss: 0.8572 - val_F1: 0.4404 - val_EM: 0.0000e+00\n",
      "Epoch 51/60\n",
      "9675/9675 [==============================] - 1100s 114ms/step - accuracy: 0.9996 - loss: 0.0147 - F1: nan - EM: 0.1673 - lr: 1.9000e-04 - val_accuracy: 0.9610 - val_loss: 0.8648 - val_F1: 0.4443 - val_EM: 0.0000e+00\n",
      "Epoch 52/60\n",
      "9675/9675 [==============================] - 1100s 114ms/step - accuracy: 0.9996 - loss: 0.0142 - F1: 0.8892 - EM: 0.1809 - lr: 1.9000e-04 - val_accuracy: 0.9601 - val_loss: 0.8913 - val_F1: 0.4356 - val_EM: 0.0000e+00\n",
      "Epoch 53/60\n",
      "9675/9675 [==============================] - 1100s 114ms/step - accuracy: 0.9996 - loss: 0.0140 - F1: 0.8914 - EM: 0.1812 - lr: 1.9000e-04 - val_accuracy: 0.9598 - val_loss: 0.9061 - val_F1: 0.4393 - val_EM: 0.0000e+00\n",
      "Epoch 54/60\n",
      "9675/9675 [==============================] - 1100s 114ms/step - accuracy: 0.9996 - loss: 0.0136 - F1: nan - EM: 0.1965 - lr: 1.9000e-04 - val_accuracy: 0.9588 - val_loss: 0.8699 - val_F1: 0.4378 - val_EM: 0.0000e+00\n",
      "Epoch 55/60\n",
      "9675/9675 [==============================] - 1098s 114ms/step - accuracy: 0.9997 - loss: 0.0130 - F1: nan - EM: 0.2105 - lr: 1.5400e-04 - val_accuracy: 0.9598 - val_loss: 0.9538 - val_F1: 0.4396 - val_EM: 0.0000e+00\n",
      "Epoch 56/60\n",
      "9675/9675 [==============================] - 1070s 111ms/step - accuracy: 0.9997 - loss: 0.0119 - F1: nan - EM: 0.2326 - lr: 1.0000e-04 - val_accuracy: 0.9587 - val_loss: 0.8865 - val_F1: 0.4389 - val_EM: 0.0000e+00\n",
      "Epoch 57/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9997 - loss: 0.0115 - F1: nan - EM: 0.2457 - lr: 1.0000e-04 - val_accuracy: 0.9589 - val_loss: 0.9417 - val_F1: 0.4437 - val_EM: 0.0000e+00\n",
      "Epoch 58/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9997 - loss: 0.0113 - F1: 0.9122 - EM: 0.2497 - lr: 1.0000e-04 - val_accuracy: 0.9583 - val_loss: 0.9434 - val_F1: 0.4413 - val_EM: 0.0000e+00\n",
      "Epoch 59/60\n",
      "9675/9675 [==============================] - 1067s 110ms/step - accuracy: 0.9998 - loss: 0.0111 - F1: 0.9147 - EM: 0.2596 - lr: 1.0000e-04 - val_accuracy: 0.9584 - val_loss: 0.9348 - val_F1: 0.4405 - val_EM: 0.0000e+00\n",
      "Epoch 60/60\n",
      "9675/9675 [==============================] - 1066s 110ms/step - accuracy: 0.9998 - loss: 0.0110 - F1: nan - EM: 0.2620 - lr: 1.0000e-04 - val_accuracy: 0.9576 - val_loss: 0.9719 - val_F1: 0.4345 - val_EM: 0.0000e+00\n",
      "Training complete, model saved\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    model.fit(tf_train_ds, epochs=epochs, steps_per_epoch=steps, callbacks=callbacks, \n",
    "              validation_data=tf_valid_ds, validation_steps=valid_steps,verbose=1)\n",
    "    if(save_model):\n",
    "        model.save_pretrained(save_dir)\n",
    "        print('Training complete, model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjsHiiSldUFa"
   },
   "source": [
    "#### Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(ds,model,tokenizer):\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(total=batch_size*len(list(ds.as_numpy_iterator()))) as bar:\n",
    "        for batch in ds:\n",
    "            input_ids = batch['input_ids']\n",
    "            output = model.generate(input_ids)\n",
    "\n",
    "            for i in range(output.shape[0]):\n",
    "                single_pred = tokenizer.decode(output[i])\n",
    "                single_pred = single_pred.replace('<pad>','')\n",
    "                single_pred = single_pred.replace('</s>','')\n",
    "                single_pred = single_pred.strip()\n",
    "                single_pred = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', single_pred)\n",
    "                preds.append(single_pred)\n",
    "                bar.update(1)\n",
    "    return preds\n",
    "\n",
    "def evaluate(df):\n",
    "    EM = []\n",
    "    F1 = []\n",
    "    \n",
    "    if dataset == 'drop': \n",
    "        col = 'answers_spans'\n",
    "        gold_col = 'spans'\n",
    "    elif dataset == 'hotpot_qa':\n",
    "        col = 'answer'\n",
    "        gold_col = ''\n",
    "    elif dataset == 'augmented':\n",
    "        col = 'answer'\n",
    "    \n",
    "    else:\n",
    "        col = 'answers'\n",
    "        gold_col = 'text'\n",
    "    for predicted,gold in tqdm(zip(df['predicted'],df[col])):\n",
    "\n",
    "        best_EM = 0\n",
    "        best_F1 = 0\n",
    "        if (dataset == 'hotpot_qa') or (dataset == 'augmented'):\n",
    "            metrics = drop_eval.get_metrics(predicted=predicted,gold=gold)\n",
    "            best_EM = metrics[0]\n",
    "            best_F1 = metrics[1]\n",
    "            \n",
    "        else:\n",
    "            for potential_answer in gold[gold_col]:\n",
    "                metrics = drop_eval.get_metrics(predicted=predicted,gold=potential_answer)\n",
    "\n",
    "                if metrics[1] > best_F1:\n",
    "                    best_EM = metrics[0]\n",
    "                    best_F1 = metrics[1]\n",
    "\n",
    "        EM.append(best_EM)\n",
    "        F1.append(best_F1)\n",
    "        \n",
    "    df['EM'] = EM\n",
    "    df['F1'] = F1\n",
    "    \n",
    "    print('Exact Match: {:0.4f}, F1: {:0.4f}'.format(df.EM.mean(),df.F1.mean()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Dev Predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561aeecb72d94a1c9120bdcef3858e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Dev Predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1b54268b3143d1ab054fc52f1e6324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Match: 0.4265, F1: 0.4771\n",
      "results for predictions on the validation data saved to:\n",
      " ./data/drop-60epochs-v0/t5-small/results/\n"
     ]
    }
   ],
   "source": [
    "if predict_train:\n",
    "    print('Making Train Predictions...')\n",
    "    preds = batch_predict(ds=tf_train_ds,model=model,tokenizer=tokenizer)\n",
    "    train_df = train_dataset.to_pandas()\n",
    "    assert len(train_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    train_df['predicted'] = preds\n",
    "    print('Evaluating Train Predictions...')\n",
    "    train_df = evaluate(train_df)\n",
    "    if save_results:\n",
    "        train_df.to_pickle(results_dir+'{}_train'.format(dataset)+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the training data saved to:\\n',results_dir)\n",
    "    \n",
    "if predict_dev:\n",
    "    print('Making Dev Predictions...')\n",
    "    preds = batch_predict(ds=tf_valid_ds,model=model,tokenizer=tokenizer)\n",
    "    valid_df = valid_dataset.to_pandas()\n",
    "    valid_df['predicted'] = preds\n",
    "    assert len(valid_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    print('Evaluating Dev Predictions...')\n",
    "    valid_df = evaluate(valid_df)\n",
    "    if save_results:\n",
    "        valid_df.to_pickle(results_dir+'{}_validation'.format(dataset)+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the validation data saved to:\\n',results_dir)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>passage</th>\n",
       "      <th>question</th>\n",
       "      <th>answers_spans</th>\n",
       "      <th>predicted</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nfl_1184</td>\n",
       "      <td>f37e81fa-ef7b-4583-b671-762fc433faa9</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Who scored the first touchdown of the game?</td>\n",
       "      <td>{'spans': ['Chaz Schilens', 'JaMarcus Russell'...</td>\n",
       "      <td>Chaz Schilens</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nfl_1184</td>\n",
       "      <td>ac6ba235-3024-4f63-a6ab-730a14def4cb</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did Kris Brown kick?</td>\n",
       "      <td>{'spans': ['2', '3', '3', '3', '3'], 'types': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nfl_1184</td>\n",
       "      <td>2c7c93f6-69ed-47cc-a5af-94a00c185a26</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Which team won the game?</td>\n",
       "      <td>{'spans': ['Raiders', 'Raiders', 'Raiders', 't...</td>\n",
       "      <td>Texans</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfl_1184</td>\n",
       "      <td>7dfd2b64-f39e-4bb4-aeb0-1900adda6018</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did both teams kick in th...</td>\n",
       "      <td>{'spans': ['2', '2', '2', '2', '2'], 'types': ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl_1184</td>\n",
       "      <td>121a8f57-7752-4373-a9ba-748b2c577cd2</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many more yards was Kris Browns's first fi...</td>\n",
       "      <td>{'spans': ['29', '20', '29', '29', '29'], 'typ...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  section_id                              query_id  \\\n",
       "0   nfl_1184  f37e81fa-ef7b-4583-b671-762fc433faa9   \n",
       "1   nfl_1184  ac6ba235-3024-4f63-a6ab-730a14def4cb   \n",
       "2   nfl_1184  2c7c93f6-69ed-47cc-a5af-94a00c185a26   \n",
       "3   nfl_1184  7dfd2b64-f39e-4bb4-aeb0-1900adda6018   \n",
       "4   nfl_1184  121a8f57-7752-4373-a9ba-748b2c577cd2   \n",
       "\n",
       "                                             passage  \\\n",
       "0   Hoping to rebound from their loss to the Patr...   \n",
       "1   Hoping to rebound from their loss to the Patr...   \n",
       "2   Hoping to rebound from their loss to the Patr...   \n",
       "3   Hoping to rebound from their loss to the Patr...   \n",
       "4   Hoping to rebound from their loss to the Patr...   \n",
       "\n",
       "                                            question  \\\n",
       "0        Who scored the first touchdown of the game?   \n",
       "1          How many field goals did Kris Brown kick?   \n",
       "2                           Which team won the game?   \n",
       "3  How many field goals did both teams kick in th...   \n",
       "4  How many more yards was Kris Browns's first fi...   \n",
       "\n",
       "                                       answers_spans      predicted   EM   F1  \n",
       "0  {'spans': ['Chaz Schilens', 'JaMarcus Russell'...  Chaz Schilens  1.0  1.0  \n",
       "1  {'spans': ['2', '3', '3', '3', '3'], 'types': ...              3  1.0  1.0  \n",
       "2  {'spans': ['Raiders', 'Raiders', 'Raiders', 't...         Texans  0.0  0.0  \n",
       "3  {'spans': ['2', '2', '2', '2', '2'], 'types': ...              2  1.0  1.0  \n",
       "4  {'spans': ['29', '20', '29', '29', '29'], 'typ...             29  1.0  1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:172: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_answer(question,passage,model,tokenizer):\n",
    "    \n",
    "    input_text = f\"question: {question} context: {passage} </s>\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text,return_tensors=\"tf\")  \n",
    "    outputs = model.generate(input_ids)\n",
    "    tokenizer.decode(outputs[0])\n",
    "    ans = tokenizer.decode(outputs[0])\n",
    "    ans = ans.replace('<pad>','')\n",
    "    ans = ans.replace('</s>','')\n",
    "    ans = ans.strip()\n",
    "    ans = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', ans)\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "question='answer_me: What percentage of penguins do not like to eat fish?'\n",
    "context = ' context: There are lots of penguins all over the world. They all like to eat different things. One study estimates that 24.3% of penguins like to eat fish.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.75\n"
     ]
    }
   ],
   "source": [
    "question='answer_me: What percentage of penguins do not like to eat fish?'\n",
    "context = ' context: There are lots of penguins all over the world. They all like to eat different things. One study estimates that 67.25% of penguins like to eat fish.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.72\n"
     ]
    }
   ],
   "source": [
    "question='answer_me: How many percent are not Marriage couples living together?'\n",
    "context = ' context: There were 664,594 households out of which 24.35% had children under the age of 18 living with them, 46.28% were Marriage living together, 11.68% had a female householder with no husband present, and 37.40% were non-families. 30.11% of all households were made up of individuals and 14.70% (4.02% male and 10.68% female) had someone living alone who was 65 years of age or older. The average household size was 2.39 and the average family size was 2.97.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.72"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100-46.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "should be: 61\n"
     ]
    }
   ],
   "source": [
    "question='answer_me: How many points did the Ravens score in their two highest scoring games combined?'\n",
    "context = ' context: Baltimore managed to beat the Jets 10-9 on the 2010 opener, but then lost a poorly-played game against Cincinnati the following week. The Ravens rebounded against the other two division teams, beating Cleveland 24-17 in Week 3 and then Pittsburgh 17-14 in Week 4. The Ravens scored a fine win (31-17) at home against Denver in Week 5. After an overtime loss to New England, they narrowly avoided losing at home to the winless Bills. Next, the Ravens hosted Miami and won 26-10, breaking that teams 4-0 road streak. On Thursday Night, the team headed to Atlanta and lost 26-21 in a game that had some criticizing the officiating. The Ravens finished the season 12-4, second in the division due to a tiebreaker with Pittsburgh, and earning a wild card spot. Baltimore headed to Kansas City and crushed the unprepared Chiefs 30-7, but once again were knocked from the playoffs by Pittsburgh in a hard-fought battle.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)\n",
    "print('should be: 61')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0\n",
      "should be: 155\n"
     ]
    }
   ],
   "source": [
    "question='answer_me: How many yards of field goals did Gould kick?'\n",
    "context = ' context: Trying to snap a six-game losing skid, the Lions returned home for an NFC North rematch the-now 2-time NFC North champion Chicago Bears.  In the first quarter, the Bears struck first with kicker Robbie Gould nailing a 36-yard field goal.  Afterwards, the Lions took the lead with QB Jon Kitna completing a 23-yard TD pass to TE Dan Campbell.  In the second quarter, Chicago bounced back with QB Rex Grossman completing a 13-yard TD pass to WR Bernard Berrian.  Afterwards, RB Adrian Peterson got a 2-yard TD run.  In the third quarter, Detroit retook the lead with Kitna completing a 20-yard TD pass to WR Mike Furrey and a 2-yard TD pass to WR Roy Williams.  However, in the fourth quarter, the inconsistency that continues to plague the Lions showed as the Bears won with Gould getting a 36-yard field goal, a 39-yard field goal, and a 44-yard field goal and on a dropped pass by Mike Williams in the endzone on the last play of the game.  With their seventh-straight loss, the Lions fell to 2-13 as they were swept by their division rivals.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)\n",
    "print('should be: 155')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.7\n",
      "should be: 23.2\n"
     ]
    }
   ],
   "source": [
    "question='answer_me: How many more people, in terms of percentage, were in the 2nd and 3rd largest age groups combined compared to the largest?'\n",
    "context = ' context: In the county, the population was spread out with 30.20% under the age of 18, 9.30% from 18 to 24, 45.90% from 25 to 44, 20.10% from 45 to 64, and 14.60% who were 65 years of age or older.  The median age was 37 years. For every 100 females there were 95.90 males.  For every 100 females age 18 and over, there were 92.50 males.'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)\n",
    "print('should be: 23.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.399999999999999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30.2+20.1-45.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.200000000000003"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26.2+23.5-26.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.non_trainable_weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valid_df[['query_id','passage','question','answers_spans','predicted','EM','F1']].sample(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "question='question:  How many people in total would occupy 6 square miles of this county based on the population density in the census of 2000?'\n",
    "context = ' context:  As of the census of 2000, there were 445,342 people, 169,162 households, and 114,015 families residing in the county.  The population density was 615 people per square mile (238/km²).  There were 178,913 housing units at an average density of 247 per square mile (95/km²).  The racial makeup of the county was 82.19% Race (United States Census), 1.15% Race (United States Census) or Race (United States Census), 0.65% Race (United States Census), 6.68% Race (United States Census), 0.30% Race (United States Census), 5.86% from Race (United States Census), and 3.17% from two or more races.  11.17% of the population were Race (United States Census) or Race (United States Census) of any race. 17.2% were of German American, 9.9% English American, 8.2% Irish American, and 6.7% Americans ancestry. 81.7% spoke only English at home, while 9.6% spoke Spanish and 1.2% Vietnamese.'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer(question,passage,model,tokenizer):\n",
    "    \n",
    "    input_text = f\"question: {question} context: {passage} </s>\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text,return_tensors=\"tf\")  \n",
    "    outputs = model.generate(input_ids)\n",
    "    tokenizer.decode(outputs[0])\n",
    "\n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[2].weights[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cells to explore the model a bit\n",
    "\n",
    "(make these raw cells into code cells to explore)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('embeddings layer: ', model.layers[0].weights[0].name)\n",
    "print('shape: ',model.layers[0].weights[0].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[1].weights[49].trainable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[1].weights[49].trainable = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[1].weights[49].trainable"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "for x in range(len(model.layers[1].weights)):\n",
    "    weights = model.layers[1].weights[x]\n",
    "    print('layer: ',x)\n",
    "    print('   - '+weights.name)\n",
    "    print('shape: ',weights.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for x in range(len(model.layers[1].weights)):\n",
    "    weights = model.layers[1].weights[x]\n",
    "    print('layer: ',x)\n",
    "    print('   - '+weights.name)\n",
    "    print('shape: ',weights.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for item in tf_valid_ds:\n",
    "    inputs = item\n",
    "    outputs = model(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outputs['logits']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T5_DROP_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
