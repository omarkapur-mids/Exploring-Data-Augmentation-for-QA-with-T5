{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "load_model = False\n",
    "train_model = True\n",
    "use_learning_schedule = False\n",
    "save_preprocessing = True #add\n",
    "load_preprocessing = False #add\n",
    "save_results = False\n",
    "predict_train = False\n",
    "predict_dev = True\n",
    "\n",
    "run_toy = True\n",
    "toy_size = 1000\n",
    "epochs = 3\n",
    "batch_size = 8\n",
    "VERSION=\"train-on-drop-only\"\n",
    "t5_model = 't5-small'\n",
    "\n",
    "warmup_steps = 10 #1e4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47S35TVwgIeG",
    "tags": []
   },
   "source": [
    "# Using T5 on DROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUEAtP-egIeI"
   },
   "source": [
    "#### Package installs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "xKtbsamsidKs"
   },
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece\n",
    "!pip install --quiet wget\n",
    "!pip install --quiet datasets\n",
    "#!pip install --quiet ipywidgets\n",
    "#!pip install --quiet tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAC1x24qgIeJ"
   },
   "source": [
    "#### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyexkfSDij_3",
    "outputId": "6f764bbb-097b-4fc0-dd92-bfe8b5a65292"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2EQCkymgIeK"
   },
   "source": [
    "#### Download drop_eval module and set directories\n",
    "\n",
    "https://github.com/allenai/allennlp-reading-comprehension/blob/master/allennlp_rc/eval/drop_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xME0lIMVgIeK",
    "outputId": "161c6687-c3c8-40c2-a9cd-efe68926a933",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py -O drop_eval.py\n",
    "\n",
    "#set directories\n",
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    !mkdir data\n",
    "data_dir = f\"./data/{VERSION}/{t5_model}\"\n",
    "if not os.path.exists(data_dir):\n",
    "    !mkdir $data_dir\n",
    "else:\n",
    "    if save_model: print(f'!!!!!{VERSION} directory already created locally -- CAUTION -- this run may overwrite existing data!!!!!')\n",
    "    else: print('NOTE: save_model == FALSE, this execution will not save the model locally')\n",
    "    \n",
    "results_dir = f\"{data_dir}/results/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    !mkdir $results_dir\n",
    "\n",
    "log_dir = f\"{data_dir}/experiments/logs\"\n",
    "save_path = f\"{data_dir}/experiments/models\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ADai1tgIeL"
   },
   "source": [
    "#### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w1GhOTfgIeM"
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "# logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow.keras as keras\n",
    "import drop_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm,trange\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "assert len(tf.config.list_physical_devices(\"GPU\")) > 0, \"No GPU found by Tensorflow\"\n",
    "\n",
    "if(run_toy): print(f'Running on {toy_size:,} records for development run')\n",
    "    \n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5goXuHR1gIeM"
   },
   "source": [
    "#### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdP6lcFegIeM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class T5forDrop(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        tf.keras.metrics.Mean(name='loss') \n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "XdP6lcFegIeM",
    "tags": []
   },
   "source": [
    "class T5forDrop(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker=tf.keras.metrics.Mean(name='loss') \n",
    "        self.F1_tracker= tf.keras.metrics.Mean(name='F1')\n",
    "        self.EM_tracker= tf.keras.metrics.Mean(name='EM')\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y_true = x['labels']\n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            y_pred = outputs['logits']\n",
    "            loss = tf.reduce_mean(outputs['loss'])\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        tf.print(y_pred,y_true)\n",
    "        metri = tf.map_fn(lambda y: drop_eval.get_metrics(predicted=y[0],gold=y[1]),(y_pred,y_true))\n",
    "        print(metri)\n",
    "#         EM, F1 = drop_eval.get_metrics(predicted=y_pred,gold=y)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.F1_tracker.update_state(F1)\n",
    "        self.EM_tracker.update_state(EM)\n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "\n",
    "        \n",
    "        \n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esxfDrXO66Bz"
   },
   "source": [
    "#### Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r08M8aqE65_M",
    "outputId": "6fa4e62d-e0a1-419d-f167-370905df422c"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "#replace numbers with special tokens\n",
    "numbers = {'additional_special_tokens':['1','2','3','4','5','6','7','8','9','0','<ss>','<sv>']}\n",
    "num_tokens_added = tokenizer.add_special_tokens(numbers)\n",
    "\n",
    "\n",
    "model = T5forDrop.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIt7bbI8gIeN"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy(dataset,toy_size=1000):\n",
    "    df = dataset.to_pandas()\n",
    "    df = df.head(toy_size)\n",
    "    return Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaxF09BQgIeO",
    "outputId": "7c233bba-6248-40ef-b87f-6fb31d5a42df"
   },
   "outputs": [],
   "source": [
    "train_dataset_full = load_dataset('drop', split='train')\n",
    "valid_dataset_full = load_dataset('drop', split='validation')\n",
    "\n",
    "print('Dataset features: ',train_dataset_full.features)\n",
    "\n",
    "#reduce data to toy size if run_toy flag is set\n",
    "if(run_toy):\n",
    "    train_dataset = make_toy(train_dataset_full)\n",
    "    valid_dataset = make_toy(valid_dataset_full)\n",
    "\n",
    "else:\n",
    "    train_dataset = train_dataset_full\n",
    "    valid_dataset = valid_dataset_full\n",
    "    \n",
    "#check out one record\n",
    "data = next(iter(valid_dataset))\n",
    "print(\"\\n\\nExample data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo9sZK0bgIeS"
   },
   "source": [
    "#### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int(np.ceil(len(train_dataset)/batch_size))\n",
    "valid_steps = int(np.ceil(len(valid_dataset)/batch_size))\n",
    "print('Training datset size: {:,} records'.format(len(train_dataset)))\n",
    "print('Validation datset size: {:,} records'.format(len(valid_dataset)))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print(\"Total Steps: {:,}\".format(steps))\n",
    "print(\"Total Validation Steps: {:,}\".format(valid_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZCcTPA0gIeS"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnCSjtGwgIeT"
   },
   "outputs": [],
   "source": [
    "def encode(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "    context = example['passage']\n",
    "    question = example['question']\n",
    "    \n",
    "    answer = example['answers_spans']['spans']\n",
    "    answer_type = example['answers_spans']['types']\n",
    "    \n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)}\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus}\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention,\n",
    "                }\n",
    "    return outputs\n",
    "    \n",
    "def to_tf_dataset(dataset):\n",
    "    '''convert from arrow to TF dataset'''\n",
    "    \n",
    "    columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "    dataset.set_format(type='tensorflow', columns=columns)\n",
    "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,}\n",
    "    return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None]),}\n",
    "    ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "    return ds\n",
    "\n",
    "def create_dataset(dataset, cache_path=None, batch_size=batch_size, \n",
    "                   buffer_size= 1000, shuffling=True):\n",
    "    '''returns a padded_batch tf dataset'''\n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.padded_batch(batch_size)\n",
    "#     dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xiO1_gwgIeT",
    "outputId": "193cc551-b130-4c86-f566-e3d62cd1ee84"
   },
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "train_ds = train_dataset.map(encode)\n",
    "valid_ds = valid_dataset.map(encode)\n",
    "\n",
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_train_ds = tf_train_ds.repeat(epochs)\n",
    "\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "\n",
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)\n",
    "\n",
    "print('dataset schema:')\n",
    "tf_train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHAi1i2BgIeV"
   },
   "source": [
    "#### Callbacks and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsCNpoMEgIeV"
   },
   "outputs": [],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5,name='accuracy') ]#[drop_eval.get_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc5HnwUwgIeV"
   },
   "source": [
    "#### Compile and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_learning_schedule:\n",
    "    learning_rate = CustomSchedule(d_model)\n",
    "else:\n",
    "    learning_rate = 0.0005\n",
    "    \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjHtw6LogIeV"
   },
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.fit(tf_train_ds, epochs=epochs, steps_per_epoch=steps, callbacks=callbacks, \n",
    "              validation_data=tf_valid_ds, validation_steps=valid_steps,verbose=1)\n",
    "    if(save_model):\n",
    "        model.save_pretrained(save_path)\n",
    "        print('Training complete, model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqxSSq06bZct"
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_weights(save_path+'/tf_model.h5')\n",
    "    print(f'Model loaded from {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjsHiiSldUFa"
   },
   "source": [
    "#### Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(ds,model,tokenizer):\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(total=batch_size*len(list(ds.as_numpy_iterator()))) as bar:\n",
    "        for batch in ds:\n",
    "            input_ids = batch['input_ids']\n",
    "            output = model.generate(input_ids)\n",
    "\n",
    "            for i in range(output.shape[0]):\n",
    "                single_pred = tokenizer.decode(output[i])\n",
    "                single_pred = single_pred.replace('<pad>','')\n",
    "                single_pred = single_pred.replace('</s>','')\n",
    "                single_pred = single_pred.strip()\n",
    "                single_pred = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', single_pred)\n",
    "                preds.append(single_pred)\n",
    "                bar.update(1)\n",
    "    return preds\n",
    "\n",
    "def evaluate(df):\n",
    "    EM = []\n",
    "    F1 = []\n",
    "    \n",
    "    \n",
    "    for predicted,gold in tqdm(zip(df['predicted'],df['answers_spans'])):\n",
    "\n",
    "        best_EM = 0\n",
    "        best_F1 = 0\n",
    "\n",
    "        for potential_answer in gold['spans']:\n",
    "            metrics = drop_eval.get_metrics(predicted=predicted,gold=potential_answer)\n",
    "\n",
    "            if metrics[1] > best_F1:\n",
    "                best_EM = metrics[0]\n",
    "                best_F1 = metrics[1]\n",
    "\n",
    "        EM.append(best_EM)\n",
    "        F1.append(best_F1)\n",
    "        \n",
    "    df['EM'] = EM\n",
    "    df['F1'] = F1\n",
    "    \n",
    "    print('Exact Match: {:0.4f}, F1: {:0.4f}'.format(df.EM.mean(),df.F1.mean()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_train:\n",
    "    print('Making Train Predictions...')\n",
    "    preds = batch_predict(ds=tf_train_ds,model=model,tokenizer=tokenizer)\n",
    "    train_df = train_dataset.to_pandas()\n",
    "    assert len(train_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    train_df['predicted'] = preds\n",
    "    print('Evaluating Train Predictions...')\n",
    "    train_df = evaluate(train_df)\n",
    "    if save_results:\n",
    "        train_df.to_pickle(results_dir+'drop_train'+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the training data saved to:\\n',save_path)\n",
    "    \n",
    "if predict_dev:\n",
    "    print('Making Dev Predictions...')\n",
    "    preds = batch_predict(ds=tf_valid_ds,model=model,tokenizer=tokenizer)\n",
    "    valid_df = valid_dataset.to_pandas()\n",
    "    valid_df['predicted'] = preds\n",
    "    assert len(valid_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    print('Evaluating Dev Predictions...')\n",
    "    valid_df = evaluate(valid_df)\n",
    "    if save_results:\n",
    "        valid_df.to_pickle(results_dir+'drop_validation'+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the validation data saved to:\\n',save_path)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df[['query_id','passage','question','answers_spans','predicted','EM','F1']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(query_id,df):\n",
    "    print('question: ',df.loc[df.query_id == query_id,'question'].iloc[0])\n",
    "    print('passage: ',df.loc[df.query_id == query_id,'passage'].iloc[0])\n",
    "    print('\\npredicted answer: ',df.loc[df.query_id == query_id,'predicted'].iloc[0])\n",
    "    print('True answers: ',df.loc[df.query_id == query_id,'answers_spans'].iloc[0])\n",
    "    print('F1 score: ',df.loc[df.query_id == query_id,'F1'].iloc[0])\n",
    "    print('EM score: ',df.loc[df.query_id == query_id,'EM'].iloc[0])\n",
    "    \n",
    "    \n",
    "query_id = '0686d1f9-4a8e-4031-b665-49d425afb777'\n",
    "print_example(query_id,valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = '86dd1721-6bf4-45fa-b01e-de47e4f7301d'\n",
    "print_example(query_id,valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = 'ad19857f-cd76-4d01-ba29-1a589cfee053'\n",
    "print_example(query_id,valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cells to explore the model a bit\n",
    "\n",
    "(make these raw cells into code cells to explore)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('embeddings layer: ', model.layers[0].weights[0].name)\n",
    "print('shape: ',model.layers[0].weights[0].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for x in range(len(model.layers[2].weights)):\n",
    "    weights = model.layers[2].weights[x]\n",
    "    print('layer: ',x)\n",
    "    print('   - '+weights.name)\n",
    "    print('shape: ',weights.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for x in range(len(model.layers[1].weights)):\n",
    "    weights = model.layers[1].weights[x]\n",
    "    print('layer: ',x)\n",
    "    print('   - '+weights.name)\n",
    "    print('shape: ',weights.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(model.layers[1].weights)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tf_valid_ds:\n",
    "    inputs = item\n",
    "    outputs = model(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T5_DROP_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
