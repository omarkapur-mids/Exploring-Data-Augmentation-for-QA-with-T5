{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47S35TVwgIeG",
    "tags": []
   },
   "source": [
    "# Exploring Data Augmentation for Question Answering with T5\n",
    "### Omar Kapur, Phillip Ng, Amber Rashid\n",
    "#### W266, Summer 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## decide which size of T5 to use\n",
    "t5_model = 't5-small'\n",
    "#choose whether to save the model that will be trained\n",
    "save_model = True\n",
    "VERSION=\"augmented-drop-50percent-30\"\n",
    "#choose whether to load the weights of a previously trained model\n",
    "load_model = False\n",
    "load_version = ''\n",
    "#choose whether to train the model\n",
    "train_model = True\n",
    "#choose whether to use a learning rate scheduler with warm-up & decay\n",
    "use_learning_schedule = True\n",
    "\n",
    "#choose whether to predict on train and/or dev sets\n",
    "predict_train = False\n",
    "predict_dev = True\n",
    "#choose whether to save prediction results to pickle folder\n",
    "save_results = True\n",
    "\n",
    "#choose number of epochs\n",
    "epochs = 30\n",
    "#choose batch size\n",
    "batch_size = 8\n",
    "#choose dataset to use\n",
    "dataset='augmented_drop' #acceptable values: drop, squad, hotpot_qa, augmented, augmented_drop\n",
    "augmented_file = 'drop-augmented-50.pkl' #acceptable values: drop-augmented-5.pkl, drop-augmented-10.pkl, drop-augmented-25.pkl, drop-augmented-25.pkl\n",
    "\n",
    "#choose whether to run a toy size dataset\n",
    "run_toy = False\n",
    "toy_size = 1000\n",
    "\n",
    "#additional parameters\n",
    "encoder_max_len = 512 #250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUEAtP-egIeI"
   },
   "source": [
    "#### Package installs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "xKtbsamsidKs"
   },
   "source": [
    "!pip install --quiet transformers\n",
    "!pip install --quiet sentencepiece\n",
    "!pip install --quiet wget\n",
    "!pip install --quiet datasets\n",
    "#!pip install --quiet ipywidgets\n",
    "#!pip install --quiet tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAC1x24qgIeJ"
   },
   "source": [
    "#### check gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyexkfSDij_3",
    "outputId": "6f764bbb-097b-4fc0-dd92-bfe8b5a65292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 30 09:27:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P8    49W / 420W |    490MiB / 24265MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1442      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A      8340      G   /usr/lib/xorg/Xorg                232MiB |\n",
      "|    0   N/A  N/A      8509      G   /usr/bin/gnome-shell               75MiB |\n",
      "|    0   N/A  N/A     15781      G   ...AAAAAAAAA= --shared-files       36MiB |\n",
      "|    0   N/A  N/A   1140745      G   ...AAAAAAAAA= --shared-files       74MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2EQCkymgIeK"
   },
   "source": [
    "#### Download drop_eval module and set directories\n",
    "\n",
    "https://github.com/allenai/allennlp-reading-comprehension/blob/master/allennlp_rc/eval/drop_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-30 09:27:15--  https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11222 (11K) [text/plain]\n",
      "Saving to: ‘drop_eval.py’\n",
      "\n",
      "drop_eval.py        100%[===================>]  10.96K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2021-07-30 09:27:15 (2.63 MB/s) - ‘drop_eval.py’ saved [11222/11222]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/allenai/allennlp-reading-comprehension/master/allennlp_rc/eval/drop_eval.py -O drop_eval.py\n",
    "import os\n",
    "def create_dir(d,verbose=False):\n",
    "    if not os.path.exists(d):\n",
    "        !mkdir -p $d    \n",
    "        if verbose: print(f'created folder for {d}')\n",
    "    else:\n",
    "        if verbose: print(f'using existing folder for {d}\\nCAUTION -- this run may overwrite existing data!')\n",
    "    \n",
    "#set directories\n",
    "root_dir = './data'\n",
    "data_dir = f\"./data/{VERSION}/{t5_model}\"\n",
    "augmented_dir = f\"{root_dir}/augmented-data\"\n",
    "results_dir = f\"{data_dir}/results/\"\n",
    "log_dir = f\"{data_dir}/experiments/logs\"\n",
    "save_dir = f\"{data_dir}/experiments/models\"\n",
    "load_dir = f\"{root_dir}/{load_version}/{t5_model}/experiments/models\"\n",
    "\n",
    "create_dir(root_dir)\n",
    "create_dir(data_dir)\n",
    "create_dir(augmented_dir)\n",
    "create_dir(results_dir)\n",
    "create_dir(log_dir)\n",
    "create_dir(save_dir)\n",
    "\n",
    "if load_model:\n",
    "    assert os.path.exists(load_dir), 'Error - trying to load a model that doesnt exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ADai1tgIeL"
   },
   "source": [
    "#### load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4w1GhOTfgIeM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 09:27:21.140206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Wed_Jun__2_19:15:15_PDT_2021\n",
      "Cuda compilation tools, release 11.4, V11.4.48\n",
      "Build cuda_11.4.r11.4/compiler.30033411_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 09:27:22.379374: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-30 09:27:22.391100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:22.391853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-30 09:27:22.391869: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-30 09:27:22.394055: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-30 09:27:22.394083: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-30 09:27:22.395243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-30 09:27:22.395387: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-30 09:27:22.395663: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-30 09:27:22.396136: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-30 09:27:22.396225: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-30 09:27:22.396284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:22.397046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:22.397765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow.keras as keras\n",
    "import drop_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm,trange\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "assert len(tf.config.list_physical_devices(\"GPU\")) > 0, \"No GPU found by Tensorflow\"\n",
    "\n",
    "if(run_toy): print(f'Running on {toy_size:,} records for development run')\n",
    "    \n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5goXuHR1gIeM"
   },
   "source": [
    "#### Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XdP6lcFegIeM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class T5forDrop(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss')\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esxfDrXO66Bz"
   },
   "source": [
    "#### Import model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r08M8aqE65_M",
    "outputId": "6fa4e62d-e0a1-419d-f167-370905df422c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 09:27:28.369309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-30 09:27:28.371775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.374520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-07-30 09:27:28.374710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.376907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.378572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-30 09:27:28.378630: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-30 09:27:28.680657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-30 09:27:28.680678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-30 09:27:28.680684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-30 09:27:28.680844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.681662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.682380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-30 09:27:28.683075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21832 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2021-07-30 09:27:28.855699: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2021-07-30 09:27:28.923233: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-30 09:27:29.376965: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-30 09:27:29.377005: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing T5forDrop.\n",
      "\n",
      "All the layers of T5forDrop were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5forDrop for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(t5_model)\n",
    "#replace numbers with special tokens\n",
    "numbers = {'additional_special_tokens':['1','2','3','4','5','6','7','8','9','0','<ss>','<sv>']}\n",
    "num_tokens_added = tokenizer.add_special_tokens(numbers)\n",
    "\n",
    "\n",
    "model = T5forDrop.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIt7bbI8gIeN"
   },
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_toy(dataset,toy_size=1000):\n",
    "    df = dataset.to_pandas()\n",
    "    df = df.head(toy_size)\n",
    "    return Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaxF09BQgIeO",
    "outputId": "7c233bba-6248-40ef-b87f-6fb31d5a42df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded augmented drop datafile: drop-augmented-50.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n",
      "Using custom data configuration default\n",
      "Reusing dataset drop (/home/omar/.cache/huggingface/datasets/drop/default/0.1.0/393cc04823935c1302a6a7e380cdbe9f452d37858ea276409787c983748eae25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:  {'section_id': Value(dtype='string', id=None), 'query_id': Value(dtype='string', id=None), 'passage': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers_spans': {'spans': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'types': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, 'source': Value(dtype='string', id=None), 'index': Value(dtype='float64', id=None), 'context': Value(dtype='string', id=None), 'answer': Value(dtype='string', id=None), 'qtype': Value(dtype='string', id=None), 'topic': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n",
      "\n",
      "\n",
      "Example data from the dataset: \n",
      " {'section_id': 'nfl_1184', 'query_id': 'f37e81fa-ef7b-4583-b671-762fc433faa9', 'passage': \" Hoping to rebound from their loss to the Patriots, the Raiders stayed at home for a Week 16 duel with the Houston Texans.  Oakland would get the early lead in the first quarter as quarterback JaMarcus Russell completed a 20-yard touchdown pass to rookie wide receiver Chaz Schilens.  The Texans would respond with fullback Vonta Leach getting a 1-yard touchdown run, yet the Raiders would answer with kicker Sebastian Janikowski getting a 33-yard and a 30-yard field goal.  Houston would tie the game in the second quarter with kicker Kris Brown getting a 53-yard and a 24-yard field goal. Oakland would take the lead in the third quarter with wide receiver Johnnie Lee Higgins catching a 29-yard touchdown pass from Russell, followed up by an 80-yard punt return for a touchdown.  The Texans tried to rally in the fourth quarter as Brown nailed a 40-yard field goal, yet the Raiders' defense would shut down any possible attempt.\", 'question': 'Who scored the first touchdown of the game?', 'answers_spans': {'spans': ['Chaz Schilens', 'JaMarcus Russell'], 'types': ['span', 'span']}}\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"hotpot_qa\":\n",
    "    train_dataset_full = load_dataset(dataset,'distractor',split='train')\n",
    "    \n",
    "elif dataset == 'augmented':\n",
    "    full_df = pd.read_pickle(augmented_dir+'/augmented_data.pkl')\n",
    "    train_dataset_full = Dataset.from_pandas(full_df)\n",
    "    \n",
    "elif dataset == 'augmented_drop':\n",
    "    aug_df = pd.read_pickle(augmented_dir+'/'+augmented_file)\n",
    "    print('loaded augmented drop datafile: {}\\n'.format(augmented_file))\n",
    "    aug_df['source'] = 'augmented'\n",
    "    drop_train_dataset = load_dataset('drop',split='train')\n",
    "    drop_df = drop_train_dataset.to_pandas()\n",
    "    drop_df['source'] = 'drop'\n",
    "    train_df_full = pd.concat([drop_df,aug_df])\n",
    "    train_dataset_full = Dataset.from_pandas(train_df_full)\n",
    "    \n",
    "elif dataset == 'drop':\n",
    "    train_dataset_full = load_dataset(dataset,split='train')\n",
    "else:\n",
    "    train_dataset_full = load_dataset(dataset,split='train')\n",
    "\n",
    "#always use drop validation dataset\n",
    "valid_dataset_full = load_dataset('drop', split='validation')\n",
    "\n",
    "print('Dataset features: ',train_dataset_full.features)\n",
    "\n",
    "#reduce data to toy size if run_toy flag is set\n",
    "if(run_toy):\n",
    "    train_dataset = make_toy(train_dataset_full)\n",
    "    valid_dataset = make_toy(valid_dataset_full)\n",
    "\n",
    "else:\n",
    "    train_dataset = train_dataset_full\n",
    "    valid_dataset = valid_dataset_full\n",
    "    \n",
    "#check out one record\n",
    "data = next(iter(valid_dataset))\n",
    "print(\"\\n\\nExample data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo9sZK0bgIeS"
   },
   "source": [
    "#### set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training datset size: 116,400 records\n",
      "Validation datset size: 9,535 records\n",
      "Batch size: 8\n",
      "Total Steps: 14,550\n",
      "Total Validation Steps: 1,192\n"
     ]
    }
   ],
   "source": [
    "steps = int(np.ceil(len(train_dataset)/batch_size))\n",
    "valid_steps = int(np.ceil(len(valid_dataset)/batch_size))\n",
    "print('Training datset size: {:,} records'.format(len(train_dataset)))\n",
    "print('Validation datset size: {:,} records'.format(len(valid_dataset)))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print(\"Total Steps: {:,}\".format(steps))\n",
    "print(\"Total Validation Steps: {:,}\".format(valid_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZCcTPA0gIeS"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GnCSjtGwgIeT"
   },
   "outputs": [],
   "source": [
    "def encode_train(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "\n",
    "    if dataset == 'drop':\n",
    "        context = example['passage']\n",
    "        question = example['question']\n",
    "\n",
    "        answer = example['answers_spans']['spans']\n",
    "        answer_type = example['answers_spans']['types']\n",
    "    elif dataset == 'squad':\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        \n",
    "        answer = example['answers']['text']\n",
    "        answer_type = 'text'\n",
    "    elif dataset == 'hotpot_qa':\n",
    "        context = ''\n",
    "        for sentence in example[\"context\"][\"sentences\"]:\n",
    "            context += \" \".join(sentence) + \" \"\n",
    "        question = example['question']\n",
    "        \n",
    "        answer = [example['answer']]\n",
    "        answer_type = 'text'    \n",
    "    elif dataset == 'augmented':\n",
    "        context = example['context']\n",
    "        question = example['question']\n",
    "        answer = [example['answer']]\n",
    "        answer_type = example['qtype']\n",
    "    elif dataset == 'augmented_drop':\n",
    "        if(example['source'] == 'drop'):\n",
    "            context = example['passage']\n",
    "            question = example['question']\n",
    "            answer = example['answers_spans']['spans']\n",
    "            answer_type = example['answers_spans']['types']\n",
    "        else:\n",
    "            context = example['context']\n",
    "            question = example['question']\n",
    "            answer = [example['answer']]\n",
    "            answer_type = example['qtype']\n",
    "    \n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)}\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus}\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention,\n",
    "                }\n",
    "    return outputs\n",
    "\n",
    "def encode_drop(example,\n",
    "           encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "\n",
    "    context = example['passage']\n",
    "    question = example['question']\n",
    "\n",
    "    answer = example['answers_spans']['spans']\n",
    "    answer_type = example['answers_spans']['types']\n",
    "\n",
    "    question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += f\" context: {str(context)}\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus}\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                              pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention,\n",
    "                }\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def to_tf_dataset(dataset):\n",
    "    '''convert from arrow to TF dataset'''\n",
    "    \n",
    "    columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "    dataset.set_format(type='tensorflow', columns=columns)\n",
    "    return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,}\n",
    "    return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None]),}\n",
    "    ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "    return ds\n",
    "\n",
    "def create_dataset(dataset, cache_path=None, batch_size=batch_size, \n",
    "                   buffer_size= 1000, shuffling=True):\n",
    "    '''returns a padded_batch tf dataset'''\n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.padded_batch(batch_size)\n",
    "#     dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xiO1_gwgIeT",
    "outputId": "193cc551-b130-4c86-f566-e3d62cd1ee84"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71ea6a4ec584961b633352f78bc81fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=116400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15af1e15f8f24d059fd6a964b5ea7c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9535.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train dataset schema:\n",
      "dev dataset schema:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'labels': TensorSpec(shape=(None, None), dtype=tf.int32, name=None),\n",
       " 'decoder_attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocess data\n",
    "\n",
    "train_ds = train_dataset.map(encode_train)\n",
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_train_ds = tf_train_ds.repeat(epochs)\n",
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "\n",
    "\n",
    "valid_ds = valid_dataset.map(encode_drop)\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)\n",
    "\n",
    "print('train dataset schema:')\n",
    "tf_train_ds.element_spec\n",
    "print('dev dataset schema:')\n",
    "tf_valid_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHAi1i2BgIeV"
   },
   "source": [
    "#### Callbacks and checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Schedule to input into CustomLearningRateScheduler()\n",
    "def lr_schedule(training_steps, lr):\n",
    "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
    "    if training_steps < __TOTAL_WARM_UP_STEPS:\n",
    "        # print(\"\\nWARM UP: Using Increasing Linear Function at Training Step:{}\".format(training_steps))\n",
    "        lr = ((MAX_LR - START_LR)/__TOTAL_WARM_UP_STEPS) * training_steps + START_LR # y = (m)x + b\n",
    "    else:\n",
    "        __CURRENT_DECAY_STEP = training_steps - __TOTAL_WARM_UP_STEPS\n",
    "        if DECAY == \"ExponentialDecay\":\n",
    "            # print(\"\\nDECAY: Using ExponentialDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = keras.optimizers.schedules.ExponentialDecay(\n",
    "                  initial_learning_rate=MAX_LR,\n",
    "                  decay_steps=__TOTAL_DECAY_STEPS,\n",
    "                  decay_rate=END_LR/MAX_LR)\n",
    "        elif DECAY == \"PiecewiseConstantDecay\":\n",
    "            # print(\"\\nDECAY: Using PiecewiseConstantDecay at Training Step:{}\".format(training_steps))\n",
    "            __CURRENT_DECAY_STEP = tf.Variable(__CURRENT_DECAY_STEP, trainable=False)\n",
    "            __DECAY_FN = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "                  __BOUNDARIES, __VALUES)\n",
    "        elif DECAY == \"PolynomialDecay\":\n",
    "            # print(\"\\nDECAY: Using PolynomialDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "                  MAX_LR,\n",
    "                  __TOTAL_DECAY_STEPS,\n",
    "                  END_LR,\n",
    "                  power=POWER)\n",
    "        elif DECAY == \"InverseTimeDecay\":\n",
    "            # print(\"DECAY: Using InverseTimeDecay at Training Step:{}\".format(training_steps))\n",
    "            __DECAY_FN = keras.optimizers.schedules.InverseTimeDecay(\n",
    "                  MAX_LR, __TIME_DECAY, 1)\n",
    "        else:\n",
    "            print(\"Please Select a Decay Function\")\n",
    "            exit\n",
    "        lr = __DECAY_FN(__CURRENT_DECAY_STEP)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learning Rate Schedule Parameters\n",
    "WARM_UP_FRACTION = 1/10 #The fraction of the training steps that will be ramping up linearly to the max LR\n",
    "START_LR = 1e-7 # must be float\n",
    "MAX_LR = 1e-3 # must be float\n",
    "END_LR = 1e-9 # must be float\n",
    "EPOCHS = epochs\n",
    "STEPS_PER_EPOCH = steps\n",
    "__TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "__TOTAL_WARM_UP_STEPS = __TOTAL_STEPS * WARM_UP_FRACTION\n",
    "__TOTAL_DECAY_STEPS = __TOTAL_STEPS - __TOTAL_WARM_UP_STEPS\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# Decay Parameters\n",
    "# ExponentialDecay - None\n",
    "# PiecewiseConstantDecay\n",
    "NUM_BOUNDARIES = 10\n",
    "__BOUNDARY_STEP = __TOTAL_DECAY_STEPS/NUM_BOUNDARIES\n",
    "__BOUNDARIES = list(np.arange(0,__TOTAL_DECAY_STEPS,__BOUNDARY_STEP))\n",
    "__PIECEWISE_STEP = (MAX_LR - END_LR)/(NUM_BOUNDARIES)\n",
    "__VALUES = list(np.arange(MAX_LR,END_LR-__PIECEWISE_STEP,-__PIECEWISE_STEP))[:len(__BOUNDARIES)+1]\n",
    "# if len(__BOUNDARIES)>\n",
    "# PolynomialDecay\n",
    "POWER = .5 # Must be > 1 to reach END_LR\n",
    "#InverseTimeDecay\n",
    "__TIME_DECAY = __TOTAL_DECAY_STEPS/(MAX_LR/END_LR-1)\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# Initialize Graphing\n",
    "decay_array = [\"ExponentialDecay\", \"PiecewiseConstantDecay\", \"PolynomialDecay\", \"InverseTimeDecay\"]\n",
    "x = range(__TOTAL_STEPS)\n",
    "fig, ax = plt.subplots(figsize=(15, 6),ncols=len(decay_array))\n",
    "fig.suptitle(f'Learing Rate Schedule', fontsize=14)\n",
    "ymax = max(START_LR,MAX_LR,END_LR)\n",
    "ymax *= 1.1\n",
    "ax[0].set_ylabel('Learning Rate')\n",
    "for i,decay_type in enumerate(decay_array):\n",
    "    DECAY = decay_type\n",
    "    lr_values = []\n",
    "    for step in x:\n",
    "        lr_values.append(lr_schedule(step,0))\n",
    "    ax[i].plot(x,lr_values)\n",
    "    ax[i].set_title(decay_type, fontsize=14, pad=11)\n",
    "    ax[i].set_xlabel('Steps')\n",
    "    ax[i].set_ylim([0,ymax])\n",
    "    if i > 0:\n",
    "        ax[i].tick_params(which='both', left=False, labelleft=False)\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# ACTION: Select Decay Type\n",
    "DECAY = \"PiecewiseConstantDecay\" #[\"ExponentialDecay\", \"PiecewiseConstantDecay\", \"PolynomialDecay\", \"InverseTimeDecay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, schedule):\n",
    "        super(CustomLearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.current_epoch += 1\n",
    "\n",
    "    def on_batch_begin(self, batch_step, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        # Get the current learning rate from model's optimizer.\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # Call schedule function to get the scheduled learning rate.\n",
    "        total_steps = batch_step + self.current_epoch * steps\n",
    "        scheduled_lr = self.schedule(total_steps, lr)\n",
    "        # Set the value back to the optimizer before this epoch starts\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        # print(\"\\nEpoch %05d: Learning rate is %6.4f.\" % (total_steps, scheduled_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YsCNpoMEgIeV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 09:46:53.784273: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-30 09:46:53.784337: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2021-07-30 09:46:53.784430: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2021-07-30 09:46:53.785343: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64::/usr/local/cuda/lib64\n",
      "2021-07-30 09:46:53.786966: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so\n",
      "2021-07-30 09:46:54.021634: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2021-07-30 09:46:54.021765: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_dir + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "if use_learning_schedule:\n",
    "    callbacks.append(CustomLearningRateScheduler(lr_schedule))\n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5,name='accuracy') ]#[drop_eval.get_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc5HnwUwgIeV"
   },
   "source": [
    "#### Compile and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"t5for_drop\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  16449536  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  18881280  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  25175808  \n",
      "=================================================================\n",
      "Total params: 60,506,626\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(START_LR, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xqxSSq06bZct"
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_weights(load_dir+'/tf_model.h5')\n",
    "    print(f'Model loaded from {load_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1e53e8655d8d4436\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1e53e8655d8d4436\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wjHtw6LogIeV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 09:47:05.326591: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-30 09:47:05.602873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3504000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14550/14550 [==============================] - 1456s 99ms/step - accuracy: 0.9746 - loss: 0.3038 - lr: 1.6675e-04 - val_accuracy: 0.9560 - val_loss: 0.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_24_layer_call_fn, dropout_24_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "    9/14550 [..............................] - ETA: 23:02 - accuracy: 0.9920 - loss: 0.0727 - lr: 3.3349e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 10:11:37.743419: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2021-07-30 10:11:37.743437: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  110/14550 [..............................] - ETA: 25:22 - accuracy: 0.9928 - loss: 0.0778 - lr: 3.3465e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 10:11:48.475104: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-07-30 10:11:48.478973: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\n",
      "2021-07-30 10:11:49.472297: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 269407 callback api events and 271587 activity events. \n",
      "2021-07-30 10:11:52.856162: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14550/14550 [==============================] - 1463s 101ms/step - accuracy: 0.9920 - loss: 0.0747 - lr: 5.0005e-04 - val_accuracy: 0.9546 - val_loss: 0.5315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_24_layer_call_fn, dropout_24_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "14550/14550 [==============================] - 1451s 100ms/step - accuracy: 0.9922 - loss: 0.0738 - lr: 8.3335e-04 - val_accuracy: 0.9575 - val_loss: 0.5395\n",
      "Epoch 4/30\n",
      "14550/14550 [==============================] - 1478s 102ms/step - accuracy: 0.9925 - loss: 0.0720 - lr: 9.0001e-04 - val_accuracy: 0.9600 - val_loss: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as final_layer_norm_layer_call_fn, final_layer_norm_layer_call_and_return_conditional_losses, dropout_24_layer_call_fn, dropout_24_layer_call_and_return_conditional_losses, final_layer_norm_layer_call_fn while saving (showing 5 of 1310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "14550/14550 [==============================] - 1476s 101ms/step - accuracy: 0.9930 - loss: 0.0680 - lr: 9.0000e-04 - val_accuracy: 0.9602 - val_loss: 0.5032\n",
      "Epoch 6/30\n",
      "14550/14550 [==============================] - 1476s 101ms/step - accuracy: 0.9934 - loss: 0.0653 - lr: 8.7000e-04 - val_accuracy: 0.9617 - val_loss: 0.6062\n",
      "Epoch 7/30\n",
      "14550/14550 [==============================] - 1476s 101ms/step - accuracy: 0.9938 - loss: 0.0614 - lr: 8.0000e-04 - val_accuracy: 0.9587 - val_loss: 0.5716\n",
      "Epoch 8/30\n",
      "14550/14550 [==============================] - 1476s 101ms/step - accuracy: 0.9941 - loss: 0.0593 - lr: 8.0000e-04 - val_accuracy: 0.9649 - val_loss: 0.5642\n",
      "Epoch 9/30\n",
      "14550/14550 [==============================] - 1476s 101ms/step - accuracy: 0.9944 - loss: 0.0570 - lr: 7.4000e-04 - val_accuracy: 0.9654 - val_loss: 0.6160\n",
      "Epoch 10/30\n",
      "14550/14550 [==============================] - 1483s 102ms/step - accuracy: 0.9948 - loss: 0.0544 - lr: 7.0000e-04 - val_accuracy: 0.9670 - val_loss: 0.6452\n",
      "Epoch 11/30\n",
      "14550/14550 [==============================] - 1483s 102ms/step - accuracy: 0.9951 - loss: 0.0528 - lr: 7.0000e-04 - val_accuracy: 0.9663 - val_loss: 0.8132\n",
      "Epoch 12/30\n",
      "14550/14550 [==============================] - 1483s 102ms/step - accuracy: 0.9955 - loss: 0.0499 - lr: 6.1001e-04 - val_accuracy: 0.9660 - val_loss: 0.6143\n",
      "Epoch 13/30\n",
      "14550/14550 [==============================] - 1484s 102ms/step - accuracy: 0.9958 - loss: 0.0478 - lr: 6.0000e-04 - val_accuracy: 0.9661 - val_loss: 0.6644\n",
      "Epoch 14/30\n",
      "14550/14550 [==============================] - 1484s 102ms/step - accuracy: 0.9960 - loss: 0.0462 - lr: 5.8000e-04 - val_accuracy: 0.9678 - val_loss: 0.5709\n",
      "Epoch 15/30\n",
      "14550/14550 [==============================] - 1484s 102ms/step - accuracy: 0.9963 - loss: 0.0436 - lr: 5.0000e-04 - val_accuracy: 0.9667 - val_loss: 0.6629\n",
      "Epoch 16/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9966 - loss: 0.0421 - lr: 5.0000e-04 - val_accuracy: 0.9677 - val_loss: 0.6297\n",
      "Epoch 17/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9967 - loss: 0.0406 - lr: 4.5000e-04 - val_accuracy: 0.9695 - val_loss: 0.6230\n",
      "Epoch 18/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9970 - loss: 0.0383 - lr: 4.0000e-04 - val_accuracy: 0.9690 - val_loss: 0.6294\n",
      "Epoch 19/30\n",
      "14550/14550 [==============================] - 1488s 102ms/step - accuracy: 0.9971 - loss: 0.0373 - lr: 4.0000e-04 - val_accuracy: 0.9679 - val_loss: 0.7071\n",
      "Epoch 20/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9973 - loss: 0.0354 - lr: 3.2001e-04 - val_accuracy: 0.9655 - val_loss: 0.6852\n",
      "Epoch 21/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9975 - loss: 0.0340 - lr: 3.0000e-04 - val_accuracy: 0.9695 - val_loss: 0.6705\n",
      "Epoch 22/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9975 - loss: 0.0330 - lr: 2.9000e-04 - val_accuracy: 0.9688 - val_loss: 0.6901\n",
      "Epoch 23/30\n",
      "14550/14550 [==============================] - 1491s 102ms/step - accuracy: 0.9978 - loss: 0.0312 - lr: 2.0000e-04 - val_accuracy: 0.9701 - val_loss: 0.6985\n",
      "Epoch 24/30\n",
      "14550/14550 [==============================] - 1490s 102ms/step - accuracy: 0.9978 - loss: 0.0302 - lr: 2.0000e-04 - val_accuracy: 0.9677 - val_loss: 0.7325\n",
      "Epoch 25/30\n",
      "14550/14550 [==============================] - 1491s 103ms/step - accuracy: 0.9979 - loss: 0.0294 - lr: 1.6000e-04 - val_accuracy: 0.9682 - val_loss: 0.6856\n",
      "Epoch 26/30\n",
      "14550/14550 [==============================] - 1492s 103ms/step - accuracy: 0.9981 - loss: 0.0278 - lr: 1.0000e-04 - val_accuracy: 0.9694 - val_loss: 0.6675\n",
      "Epoch 27/30\n",
      "14550/14550 [==============================] - 1492s 103ms/step - accuracy: 0.9981 - loss: 0.0272 - lr: 1.0000e-04 - val_accuracy: 0.9688 - val_loss: 0.7131\n",
      "Epoch 28/30\n",
      "14550/14550 [==============================] - 1489s 102ms/step - accuracy: 0.9981 - loss: 0.0278 - lr: 3.0006e-05 - val_accuracy: 0.9705 - val_loss: 0.6569\n",
      "Epoch 29/30\n",
      "14550/14550 [==============================] - 1531s 105ms/step - accuracy: 0.9981 - loss: 0.0275 - lr: 1.0000e-09 - val_accuracy: 0.9705 - val_loss: 0.6569\n",
      "Epoch 30/30\n",
      "14550/14550 [==============================] - 1546s 106ms/step - accuracy: 0.9981 - loss: 0.0274 - lr: 1.0000e-09 - val_accuracy: 0.9705 - val_loss: 0.6569\n",
      "Training complete, model saved\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    model.fit(tf_train_ds, epochs=epochs, steps_per_epoch=steps, callbacks=callbacks, \n",
    "              validation_data=tf_valid_ds, validation_steps=valid_steps,verbose=1)\n",
    "    if(save_model):\n",
    "        model.save_pretrained(save_dir)\n",
    "        print('Training complete, model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjsHiiSldUFa"
   },
   "source": [
    "#### Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_predict(ds,model,tokenizer):\n",
    "    preds = []\n",
    "\n",
    "    with tqdm(total=batch_size*len(list(ds.as_numpy_iterator()))) as bar:\n",
    "        for batch in ds:\n",
    "            input_ids = batch['input_ids']\n",
    "            output = model.generate(input_ids)\n",
    "\n",
    "            for i in range(output.shape[0]):\n",
    "                single_pred = tokenizer.decode(output[i])\n",
    "                single_pred = single_pred.replace('<pad>','')\n",
    "                single_pred = single_pred.replace('</s>','')\n",
    "                single_pred = single_pred.strip()\n",
    "                single_pred = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', single_pred)\n",
    "                single_pred = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', single_pred)\n",
    "                preds.append(single_pred)\n",
    "                bar.update(1)\n",
    "    return preds\n",
    "\n",
    "def evaluate(df,ds_type='train'):\n",
    "    EM = []\n",
    "    F1 = []\n",
    "    \n",
    "    if ds_type == 'train':\n",
    "        ds = dataset\n",
    "    else:\n",
    "        ds = 'drop'\n",
    "        \n",
    "    if ds == 'drop': \n",
    "        col = 'answers_spans'\n",
    "        gold_col = 'spans'\n",
    "    elif ds == 'hotpot_qa':\n",
    "        col = 'answer'\n",
    "        gold_col = ''\n",
    "    elif ds == 'augmented':\n",
    "        col = 'answer'\n",
    "    else:\n",
    "        col = 'answers'\n",
    "        gold_col = 'text'\n",
    "    for predicted,gold in tqdm(zip(df['predicted'],df[col])):\n",
    "\n",
    "        best_EM = 0\n",
    "        best_F1 = 0\n",
    "        if (ds_type == 'train') and ((dataset == 'hotpot_qa') or (dataset == 'augmented')):\n",
    "            metrics = drop_eval.get_metrics(predicted=predicted,gold=gold)\n",
    "            best_EM = metrics[0]\n",
    "            best_F1 = metrics[1]\n",
    "            \n",
    "        else:\n",
    "            for potential_answer in gold[gold_col]:\n",
    "                metrics = drop_eval.get_metrics(predicted=predicted,gold=potential_answer)\n",
    "\n",
    "                if metrics[1] > best_F1:\n",
    "                    best_EM = metrics[0]\n",
    "                    best_F1 = metrics[1]\n",
    "\n",
    "        EM.append(best_EM)\n",
    "        F1.append(best_F1)\n",
    "        \n",
    "    df['EM'] = EM\n",
    "    df['F1'] = F1\n",
    "    \n",
    "    print('Exact Match: {:0.4f}, F1: {:0.4f}'.format(df.EM.mean(),df.F1.mean()))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Dev Predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862dbefd704e473fbf788fffd6fe3898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9536.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Dev Predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bf0a7f83884b1b8d46f44ac87e6b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Match: 0.4535, F1: 0.5031\n",
      "results for predictions on the validation data saved to:\n",
      " ./data/augmented-drop-50percent-30/t5-small/results/\n"
     ]
    }
   ],
   "source": [
    "if predict_train:\n",
    "    print('Making Train Predictions...')\n",
    "    preds = batch_predict(ds=tf_train_ds,model=model,tokenizer=tokenizer)\n",
    "    train_df = train_dataset.to_pandas()\n",
    "    assert len(train_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    train_df['predicted'] = preds\n",
    "    print('Evaluating Train Predictions...')\n",
    "    train_df = evaluate(train_df,ds_type='train')\n",
    "    if save_results:\n",
    "        train_df.to_pickle(results_dir+'{}_train'.format(dataset)+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the training data saved to:\\n',results_dir)\n",
    "    \n",
    "if predict_dev:\n",
    "    print('Making Dev Predictions...')\n",
    "    preds = batch_predict(ds=tf_valid_ds,model=model,tokenizer=tokenizer)\n",
    "    valid_df = valid_dataset.to_pandas()\n",
    "    valid_df['predicted'] = preds\n",
    "    assert len(valid_df) == len(preds), \"count mismatch, something went wrong\"\n",
    "    print('Evaluating Dev Predictions...')\n",
    "    valid_df = evaluate(valid_df,ds_type='valid')\n",
    "    if save_results:\n",
    "        valid_df.to_pickle(results_dir+'{}_validation'.format(VERSION)+datetime.datetime.now().strftime('%H%M-%h%d')+'.pkl')\n",
    "        print('results for predictions on the validation data saved to:\\n',results_dir)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question,passage,model,tokenizer):\n",
    "    \n",
    "    input_text = f\"question: {question} context: {passage} </s>\"\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text,return_tensors=\"tf\")  \n",
    "    outputs = model.generate(input_ids)\n",
    "    tokenizer.decode(outputs[0])\n",
    "    ans = tokenizer.decode(outputs[0])\n",
    "    ans = ans.replace('<pad>','')\n",
    "    ans = ans.replace('</s>','')\n",
    "    ans = ans.strip()\n",
    "    ans = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', ans)\n",
    "    ans = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', ans)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Subtraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/miniconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:172: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True answer: 10.47\n",
      "Predicted answer: 10.47\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Subtraction')\n",
    "question='answer_me: What percentage of elephants do not like to eat walnuts?'\n",
    "context = ' context: There are lots of elephants in the forest. They all like to eat different things. Sources say that 89.53% of elephants like to eat walnuts.'\n",
    "true_ans = '10.47'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Subtraction\n",
      "answer_me: What percentage of Genghis Khan's troops survived?\n",
      " context: Genghis Khan became fierce when they had lost the American Civil War against William the Conqueror. Leaders needed to be brave and help their troops win the victory. Sources say that 5.17% of Genghis Khan's troops died, after killing over triple as much of William the Conqueror's troops .\n",
      "\n",
      "True answer: 94.83\n",
      "Predicted answer: 94.83\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Subtraction')\n",
    "question=\"answer_me: What percentage of Genghis Khan's troops survived?\"\n",
    "context = \" context: Genghis Khan became fierce when they had lost the American Civil War against William the Conqueror. Leaders needed to be brave and help their troops win the victory. Sources say that 5.17% of Genghis Khan's troops died, after killing over triple as much of William the Conqueror's troops .\"\n",
    "true_ans = '94.83'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Recall\n",
      "\n",
      "True answer: 79.29\n",
      "Predicted answer: 79.29\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Recall')\n",
    "question='answer_me: What percentage of pandas like to eat fruit?'\n",
    "context = ' context: Let us talk of pandas all over the world. They like to sleep for many hours. One study estimates that 79.29% of pandas like to eat fruit.'\n",
    "true_ans = '79.29'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Grouping\n",
      "answer_me: What was the Miami Heat season record?\n",
      " context: It was a painful season for the Miami Heat. The team played only 75 games this season due to covid cancellations. In the first half of the season, they won 33 and lost 5 games. But this was just the beginning. Many wrote off the Miami Heat, but they went on to win 16 more games. The team deserves some much-needed rest before next year begins.\n",
      "\n",
      "True answer: 49-26\n",
      "Predicted answer: 49 -27\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Grouping')\n",
    "question='answer_me: What was the Miami Heat season record?'\n",
    "context = ' context: It was a painful season for the Miami Heat. The team played only 75 games this season due to covid cancellations. In the first half of the season, they won 33 and lost 5 games. But this was just the beginning. Many wrote off the Miami Heat, but they went on to win 16 more games. The team deserves some much-needed rest before next year begins.'\n",
    "true_ans = '49-26'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Sorting\n",
      "answer_me: What was the third largest species?\n",
      " context: Human are not alone on this earth, there exist various species of animals. Sources say that 27.22% of animals are pandas and 19.27% are monkeys all over the world, as the most populous species. Followed by giraffes making up 17.68%, and elephants making up 14.59%, respectively. Animals have characteristics which make them unique and are essential for their survival. Sources say that, there are only 12.35% of sharks and 8.87% of bears as the least populous species. Surprisingly, humans are animals too.\n",
      "\n",
      "True answer: giraffes\n",
      "Predicted answer: giraffes\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Sorting')\n",
    "question='answer_me: What was the third largest species?'\n",
    "context = ' context: Human are not alone on this earth, there exist various species of animals. Sources say that 27.22% of animals are pandas and 19.27% are monkeys all over the world, as the most populous species. Followed by giraffes making up 17.68%, and elephants making up 14.59%, respectively. Animals have characteristics which make them unique and are essential for their survival. Sources say that, there are only 12.35% of sharks and 8.87% of bears as the least populous species. Surprisingly, humans are animals too.'\n",
    "true_ans = 'giraffes'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Or\n",
      "answer_me: Who won the game, the 49ers or the Saints?\n",
      " context: The two division leaders, the 49ers and the Saints, played the Sunday night game yesterday. The 49ers were the first to score, with 14 points, but an interception and a fumble led to the Saints scoring 14. There was heavy rainfall in the second quarter, but even still the Saints scored 7 points while the 49ers scored 6. An even third quarter resulted in both teams scoring 7. A final run of good luck helped the 49ers to score 3 more points. The winner of this game goes on to the playoffs.This was a great game!\n",
      "\n",
      "True answer: 49ers\n",
      "Predicted answer: 49 ers\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Or')\n",
    "question='answer_me: Who won the game, the 49ers or the Saints?'\n",
    "context = ' context: The two division leaders, the 49ers and the Saints, played the Sunday night game yesterday. The 49ers were the first to score, with 14 points, but an interception and a fumble led to the Saints scoring 14. There was heavy rainfall in the second quarter, but even still the Saints scored 7 points while the 49ers scored 6. An even third quarter resulted in both teams scoring 7. A final run of good luck helped the 49ers to score 3 more points. The winner of this game goes on to the playoffs.This was a great game!'\n",
    "true_ans = '49ers'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Sort+\n",
      "answer_me: How much larger or smaller by percentage was the second largest species from the 3 smallest species combined?\n",
      " context: Animals are varied and diverse and can come from common ancestors as humans. One could say 41.32% of animals are butterflies and 21.23% are wolves in the jungle, as the most populous species. Followed by birds making up 17.05%, and rabbits making up 8.06%, respectively. Some animals can be domesticated. One could say, there are only 6.95% of cats and 5.38% of spiders as the least populous species. We should be living in harmony with other species.\n",
      "\n",
      "True answer: 0.84\n",
      "Predicted answer: 1.17\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Sort+')\n",
    "question='answer_me: How much larger or smaller by percentage was the second largest species from the 3 smallest species combined?'\n",
    "context = ' context: Animals are varied and diverse and can come from common ancestors as humans. One could say 41.32% of animals are butterflies and 21.23% are wolves in the jungle, as the most populous species. Followed by birds making up 17.05%, and rabbits making up 8.06%, respectively. Some animals can be domesticated. One could say, there are only 6.95% of cats and 5.38% of spiders as the least populous species. We should be living in harmony with other species.'\n",
    "true_ans = '0.84'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Sort+\n",
      "answer_me: How many points did the Falcons score in their 4 lowest scoring games combined?\n",
      " context: The Falcons defeated the Lions to start the season, scoring 27 and only allowing 8. They went on to win against the 49ers 35-8 but then lost to the Patriots, scoring just 17. The Falcons would then defeat the Ravens (39-16), followed by another victory against the Raiders (25-19), and after a tragic missed kick, they fell to 49ers, 49 to 18. However they could not find any luck, as they would lose to the Green Bay Packers, 25 to 9, and again to the Lions, 52 to 4. Unfortunately they could not save their season, they lost 25-18 to their rivals, and 40-14 in the final game.\n",
      "\n",
      "True answer: 44\n",
      "Predicted answer: 57\n"
     ]
    }
   ],
   "source": [
    "print('TEST: Sort+')\n",
    "question='answer_me: How many points did the Falcons score in their 4 lowest scoring games combined?'\n",
    "context = ' context: The Falcons defeated the Lions to start the season, scoring 27 and only allowing 8. They went on to win against the 49ers 35-8 but then lost to the Patriots, scoring just 17. The Falcons would then defeat the Ravens (39-16), followed by another victory against the Raiders (25-19), and after a tragic missed kick, they fell to 49ers, 49 to 18. However they could not find any luck, as they would lose to the Green Bay Packers, 25 to 9, and again to the Lions, 52 to 4. Unfortunately they could not save their season, they lost 25-18 to their rivals, and 40-14 in the final game.'\n",
    "true_ans = '44'\n",
    "\n",
    "ans = generate_answer(question,context,model,tokenizer)\n",
    "print(question)\n",
    "print(context)\n",
    "print('\\nTrue answer: {}'.format(true_ans))\n",
    "print('Predicted answer: {}'.format(ans))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T5_DROP_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
